{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2651,
     "status": "ok",
     "timestamp": 1622096231189,
     "user": {
      "displayName": "BokJin Chung",
      "photoUrl": "",
      "userId": "00013653044591416632"
     },
     "user_tz": -540
    },
    "id": "Hi0HXI_9M8lY",
    "outputId": "7862d8a5-07f4-4e67-a77b-4809b18144ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in c:\\programdata\\anaconda3\\lib\\site-packages (0.3.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hc6X4fRDKP-j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: echoAI in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#구현하는 모델에서 쓰이는 모든 activation함수는 정의하여 드린 GELU 함수를 사용해야함.\n",
    "#MultiHeadAttention에서 Head로 나눌때, 이미지를 patch로자른후 sequence로 만들때 Rearrange함수를 사용하면 편리함.(사용하지 않으셔도 됩니다)\n",
    "#CIFAR10에 대한 test accuracy가 60프로 이상인 ViT모델을 만드시오.\n",
    "!pip install echoAI\n",
    "import tensorflow as tf\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "from tensorflow.keras.activations import gelu\n",
    "GELU = lambda x : gelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "QrJci74oNV2m"
   },
   "outputs": [],
   "source": [
    "#논문[1]에서 설명하는 MultiHeadAttention을 만들어라.\n",
    "class MultiHeadedAttention(tf.keras.Model):\n",
    "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension)\n",
    "    def __init__(self, dimension, heads=8):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.heads = heads\n",
    "        self.scale = dimension ** -0.5\n",
    "\n",
    "        self.mlp_in = tf.keras.layers.Dense(dimension * 3, use_bias=False)\n",
    "        self.mlp_out = tf.keras.layers.Dense(dimension)\n",
    "\n",
    "        self.rearrange_attention = Rearrange(\n",
    "            'b n (qkv h d) -> qkv b h n d', qkv=3, h=self.heads)\n",
    "        self.rearrange_output = Rearrange('b h n d -> b n (h d)')\n",
    "        \n",
    "        \n",
    "        ############################################\n",
    "    def call(self, inputs):\n",
    "        output = None\n",
    "        ############Write your code Here############\n",
    "        query_key_value = self.mlp_in(inputs)\n",
    "        query_key_value = self.rearrange_attention(query_key_value)\n",
    "\n",
    "        query = query_key_value[0]\n",
    "        key = query_key_value[1]\n",
    "        value = query_key_value[2]\n",
    "\n",
    "        dot_product = tf.einsum('bhid,bhjd->bhij', query, key) * self.scale\n",
    "        attention = tf.nn.softmax(dot_product, axis=-1)\n",
    "\n",
    "        output = tf.einsum('bhij,bhjd->bhid', attention, value)\n",
    "        output = self.rearrange_output(output)\n",
    "        output = self.mlp_out(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ############################################\n",
    "        return output\n",
    "\n",
    "#인자로 받은 residual_function을 사용하여 real_function값을 return하여주는 Class를 만들어라.(call함수 참고)\n",
    "class ResidualBlock(tf.keras.Model):\n",
    "    def __init__(self, residual_function):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.residual_function = residual_function\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.residual_function(inputs) + inputs\n",
    "\n",
    "#인자로 받은 normfunction에 들어가기전에 LayerNormalization을 해주는 Class를 만들어라.(call함수 참고)\n",
    "class NormalizationBlock(tf.keras.Model):\n",
    "    def __init__(self, norm_function, epsilon=1e-5):\n",
    "        super(NormalizationBlock, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.norm_function = norm_function\n",
    "        self.normalize = tf.keras.layers.LayerNormalization(epsilon=epsilon)\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.norm_function(self.normalize(inputs))\n",
    "\n",
    "#논문[1]에서의 MLPBlock을 만들어라.\n",
    "class MLPBlock(tf.keras.Model):\n",
    "    #output_dimension - MLPBlock의 output dimension\n",
    "    #hidden_dimension - MLPBlock의 hidden layer dimension\n",
    "    def __init__(self, output_dimension, hidden_dimension):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.mlp_1 = tf.keras.layers.Dense(hidden_dimension)\n",
    "        self.mlp_2 = tf.keras.layers.Dense(output_dimension)\n",
    "\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = None\n",
    "        ############Write your code Here############\n",
    "        y = self.mlp_1(inputs)\n",
    "        y = GELU(y)\n",
    "        y = self.mlp_2(y)\n",
    "        output = GELU(y)\n",
    "        ############################################\n",
    "        return output\n",
    "\n",
    "#논문[1]을 읽고 TransformerEncoder를 위에서 정의한 class들을 사용하여 만들어라.\n",
    "class TransformerEncoder(tf.keras.Model):\n",
    "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), heads - MHA에서 head의 개수\n",
    "    #depth - encoder layer의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
    "    def __init__(self, dimension, depth, heads, mlp_dimension): \n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        layers_ = []\n",
    "        for _ in range(depth):\n",
    "            ############Write your code Here############\n",
    "            layers_ += [\n",
    "                ResidualBlock(\n",
    "                    NormalizationBlock(\n",
    "                        dimension,\n",
    "                        MultiHeadedAttention(\n",
    "                            dimension, heads=heads\n",
    "                        )\n",
    "                    )\n",
    "                ),\n",
    "                ResidualBlock(\n",
    "                    NormalizationBlock(\n",
    "                        dimension,\n",
    "                        MLPBlock(dimension, mlp_dimension)\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "            ############################################\n",
    "        self.layers_ = tf.keras.Sequential(layers_)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.layers_(inputs)\n",
    "\n",
    "#논문[2]를 읽고 ViT모델을 위에서 정의한 class들을 사용하여 만들어라.\n",
    "class ImageTransformer(tf.keras.Model):\n",
    "    #image_size - 이미지의 W==H의 크기(int), patch_size - 이미지를 쪼갤 patch의 크기(int)\n",
    "    #n_classes - 최종 class의 개수, batch_size - 배치사이즈\n",
    "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), depth - encoder layer의 개수\n",
    "    #heads - MHA에서 head의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
    "    #channel - input image에 대한 channel의 수\n",
    "    def __init__(\n",
    "            self, image_size, patch_size, n_classes, batch_size,\n",
    "            dimension, depth, heads, mlp_dimension, channels=3):\n",
    "        super(ImageTransformer, self).__init__()\n",
    "        assert image_size % patch_size == 0, 'invalid patch size for image size'\n",
    "\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.patch_size = patch_size\n",
    "        self.dimension = dimension\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.positional_embedding = self.add_weight(\n",
    "            \"position_embeddings\", shape=[num_patches + 1, dimension],\n",
    "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
    "        )\n",
    "        self.classification_token = self.add_weight(\n",
    "            \"classification_token\", shape=[1, 1, dimension],\n",
    "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
    "        )\n",
    "        ############Write your code Here############\n",
    "        self.embedding_mlp = tf.keras.layers.Dense(dimension)\n",
    "        self.rearrange = Rearrange(\n",
    "            'b c (h p1) (w p2) -> b (h w) (p1 p2 c)',\n",
    "            p1=self.patch_size, p2=self.patch_size\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(dimension, depth, heads, mlp_dimension)\n",
    "        self.classification_identity = tf.identity\n",
    "        self.mlp_1 = tf.keras.layers.Dense(mlp_dimension)\n",
    "        self.den = tf.keras.layers.Dense(n_classes)\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = None\n",
    "        ############Write your code Here############\n",
    "        shapes = tf.shape(inputs)\n",
    "        y = self.rearrange(inputs)\n",
    "        y = self.embedding_mlp(y)\n",
    "        cls_tokens = tf.broadcast_to(\n",
    "            self.classification_token,\n",
    "            (shapes[0], 1, self.dimension)\n",
    "        )\n",
    "        y = tf.concat((cls_tokens, inputs), axis=1)\n",
    "        y += self.positional_embedding\n",
    "        y = self.transformer(y)\n",
    "        y = self.classification_identity(y[:, 0])\n",
    "        y = self.mlp_1(y)\n",
    "        y = GELU(y)\n",
    "        \n",
    "        output = self.den(y)\n",
    "        ############################################\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def compile(self, loss_fn, **kwargs):\n",
    "        super(ImageTransformer, self).compile(**kwargs)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_accuracy = tf.keras.metrics.Accuracy('training_accuracy', dtype=tf.float32)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        def _step(inputs):\n",
    "            X, Y = inputs\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = self(X, training=True)\n",
    "                num_labels = tf.shape(logits)[-1]\n",
    "                label_mask = tf.math.logical_not(Y < 0)\n",
    "                label_mask = tf.reshape(label_mask, (-1,))\n",
    "                logits = tf.reshape(logits, (-1, num_labels))\n",
    "                logits_masked = tf.boolean_mask(logits, label_mask)\n",
    "                label_ids = tf.reshape(Y, (-1,))\n",
    "                label_ids_masked = tf.boolean_mask(label_ids, label_mask)\n",
    "                cross_entropy = self.loss_fn(label_ids_masked, logits_masked)\n",
    "                loss = tf.reduce_sum(cross_entropy) * (1.0 / self.batch_size)\n",
    "                y_pred = tf.argmax(tf.nn.softmax(logits, axis=-1), axis=-1)\n",
    "                self.train_accuracy.update_state(tf.squeeze(Y), y_pred)\n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(\n",
    "                list(zip(grads, self.trainable_variables)))\n",
    "            return cross_entropy\n",
    "\n",
    "        total_loss = self.distribute_strategy.reduce(\n",
    "            tf.distribute.ReduceOp.SUM,\n",
    "            self.distribute_strategy.run(_step, args=(data,)), axis=0\n",
    "        )\n",
    "        mean_loss = total_loss / self.batch_size\n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'mean_loss': mean_loss,\n",
    "            'train_accuracy': self.train_accuracy.result()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "cAydwOELeFba",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Training Finished===============\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "in user code:\n\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-55-145f6a933fea>:207 train_step\n        self.distribute_strategy.run(_step, args=(data,)), axis=0\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2726 call_for_each_replica\n        _require_cross_replica_or_default_context_extended(self)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:315 _require_cross_replica_or_default_context_extended\n        raise RuntimeError(error_message)\n\n    RuntimeError: Method requires being in cross-replica context, use get_replica_context().merge_call()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-aab8dff8f402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Accuracy :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: in user code:\n\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-55-145f6a933fea>:207 train_step\n        self.distribute_strategy.run(_step, args=(data,)), axis=0\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2726 call_for_each_replica\n        _require_cross_replica_or_default_context_extended(self)\n    C:\\Users\\DongSeong\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:315 _require_cross_replica_or_default_context_extended\n        raise RuntimeError(error_message)\n\n    RuntimeError: Method requires being in cross-replica context, use get_replica_context().merge_call()\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "# Download and prepare the CIFAR10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "############Write your code Here############\n",
    "train_images = train_images / 255.\n",
    "test_images = test_images / 255.\n",
    "\n",
    "############################################\n",
    "# Make image shape (BS, H, W, C) to (BS, C, H, W)\n",
    "############Write your code Here############\n",
    "(height, width, channels), _ = train_images.shape[1:],train_labels.shape[1:]\n",
    "train_images = tf.cast(train_images.reshape((-1, channels, height, width)), dtype=tf.float32)\n",
    "test_images = tf.cast(test_images.reshape((-1, channels, height, width)), dtype=tf.float32)\n",
    "\n",
    "train_dataset, test_dataset = (tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(train_images),\n",
    "                                                    tf.data.Dataset.from_tensor_slices(train_labels))),\n",
    "            tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(test_images),\n",
    "                                 tf.data.Dataset.from_tensor_slices(test_labels))))\n",
    "train_dataset, test_dataset = KerasDataset(tf.keras.datasets.cifar10).get_datasets()\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "#Initialize your model\n",
    "#Initialize optimizer and loss and compile it to the model\n",
    "############Write your code Here############\n",
    "# model = ImageTransformer(\n",
    "#         image_size=32, patch_size=4, n_classes=10, batch_size=64,\n",
    "#         dimension=64, depth=3, heads=4, mlp_dimension=128\n",
    "#     )\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# cross_entropy_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "#         from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    "#     )\n",
    "# train_distributed_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "# model.compile()\n",
    "\n",
    "# history = model.fit(train_dataset, batch_size=64, epochs=1)\n",
    "\n",
    "############################################\n",
    "\n",
    "#Train your model\n",
    "############Write your code Here############\n",
    "\n",
    "############################################\n",
    "print('==============Training Finished===============')\n",
    "\n",
    "#Evaluate your test samples\n",
    "accuracy = 0\n",
    "############Write your code Here############\n",
    "\n",
    "############################################\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy() if len(tf.config.list_physical_devices('GPU')) > 1 else tf.distribute.OneDeviceStrategy(\"GPU:0\")\n",
    "# with strategy.scope():\n",
    "model = ImageTransformer(\n",
    "    image_size=32, patch_size=4, n_classes=10, batch_size=64,\n",
    "    dimension=64, depth=3, heads=4, mlp_dimension=128\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "cross_entropy_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    ")\n",
    "train_distributed_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss_fn=cross_entropy_loss)\n",
    "model.fit(train_dataset, batch_size=64, epochs=10)\n",
    "print('Test Accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "# Download and prepare the CIFAR10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "############Write your code Here############\n",
    "(height, width, channels), _ = train_images.shape[1:],train_labels.shape[1:]\n",
    "train_images = tf.cast(train_images.reshape((-1, channels, height, width)), dtype=tf.float32) / 255.\n",
    "test_images = tf.cast(test_images.reshape((-1, channels, height, width)), dtype=tf.float32) / 255.\n",
    "train_images = tf.convert_to_tensor(train_images)\n",
    "############################################\n",
    "# Make image shape (BS, H, W, C) to (BS, C, H, W)\n",
    "############Write your code Here############\n",
    "train_dataset, test_dataset = (tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(train_images),\n",
    "                                                    tf.data.Dataset.from_tensor_slices(train_labels))),\n",
    "            tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(test_images),\n",
    "                                 tf.data.Dataset.from_tensor_slices(test_labels))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(BS, H, W, C) to (BS, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50000, 32, 3, 32), dtype=float32, numpy=\n",
       "array([[[[0.23137255, 0.24313726, 0.24705882, ..., 0.3647059 ,\n",
       "          0.5137255 , 0.40392157],\n",
       "         [0.3019608 , 0.49019608, 0.3882353 , ..., 0.4392157 ,\n",
       "          0.29411766, 0.52156866],\n",
       "         [0.4117647 , 0.27058825, 0.53333336, ..., 0.5803922 ,\n",
       "          0.4862745 , 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843138, 0.07843138, ..., 0.17254902,\n",
       "          0.41568628, 0.27450982],\n",
       "         [0.14509805, 0.39607844, 0.2627451 , ..., 0.36078432,\n",
       "          0.18039216, 0.47843137],\n",
       "         [0.33333334, 0.15294118, 0.5137255 , ..., 0.47843137,\n",
       "          0.34117648, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294, ..., 0.17254902,\n",
       "          0.4392157 , 0.30980393],\n",
       "         [0.18039216, 0.41568628, 0.29411766, ..., 0.37254903,\n",
       "          0.21176471, 0.5137255 ],\n",
       "         [0.3764706 , 0.21568628, 0.54509807, ..., 0.42745098,\n",
       "          0.28627452, 0.16470589]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 , ..., 0.18039216,\n",
       "          0.54509807, 0.3647059 ],\n",
       "         [0.22352941, 0.5764706 , 0.38431373, ..., 0.43137255,\n",
       "          0.2509804 , 0.5411765 ],\n",
       "         [0.36862746, 0.18039216, 0.47058824, ..., 0.20784314,\n",
       "          0.13333334, 0.07843138]],\n",
       "\n",
       "        [[0.7058824 , 0.54509807, 0.3764706 , ..., 0.14901961,\n",
       "          0.5568628 , 0.38039216],\n",
       "         [0.19215687, 0.5686275 , 0.38039216, ..., 0.3647059 ,\n",
       "          0.16862746, 0.5294118 ],\n",
       "         [0.32941177, 0.12941177, 0.45882353, ..., 0.3254902 ,\n",
       "          0.20784314, 0.13333334]],\n",
       "\n",
       "        [[0.69411767, 0.5647059 , 0.45490196, ..., 0.32156864,\n",
       "          0.6509804 , 0.5176471 ],\n",
       "         [0.3372549 , 0.6392157 , 0.5019608 , ..., 0.4117647 ,\n",
       "          0.27058825, 0.5647059 ],\n",
       "         [0.37254903, 0.21568628, 0.4392157 , ..., 0.48235294,\n",
       "          0.36078432, 0.28235295]]],\n",
       "\n",
       "\n",
       "       [[[0.6039216 , 0.69411767, 0.73333335, ..., 0.43137255,\n",
       "          0.41568628, 0.41960785],\n",
       "         [0.38431373, 0.42745098, 0.40784314, ..., 0.45882353,\n",
       "          0.40392157, 0.4       ],\n",
       "         [0.39607844, 0.3254902 , 0.37254903, ..., 0.30980393,\n",
       "          0.31764707, 0.27450982]],\n",
       "\n",
       "        [[0.54901963, 0.627451  , 0.6627451 , ..., 0.4       ,\n",
       "          0.52156866, 0.49803922],\n",
       "         [0.47058824, 0.6392157 , 0.6117647 , ..., 0.56078434,\n",
       "          0.53333336, 0.3764706 ],\n",
       "         [0.38039216, 0.33333334, 0.3882353 , ..., 0.2784314 ,\n",
       "          0.28627452, 0.23921569]],\n",
       "\n",
       "        [[0.54901963, 0.60784316, 0.6431373 , ..., 0.7411765 ,\n",
       "          0.85882354, 0.85490197],\n",
       "         [0.8509804 , 0.91764706, 0.9137255 , ..., 0.69411767,\n",
       "          0.69803923, 0.39607844],\n",
       "         [0.4       , 0.38039216, 0.39607844, ..., 0.2627451 ,\n",
       "          0.27058825, 0.21568628]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6862745 , 0.654902  , 0.6509804 , ..., 0.627451  ,\n",
       "          0.6392157 , 0.63529414],\n",
       "         [0.6666667 , 0.6431373 , 0.6392157 , ..., 0.2509804 ,\n",
       "          0.3019608 , 0.2       ],\n",
       "         [0.20784314, 0.27058825, 0.17254902, ..., 0.3647059 ,\n",
       "          0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705884, 0.6039216 , 0.5019608 , ..., 0.6039216 ,\n",
       "          0.7137255 , 0.69411767],\n",
       "         [0.7019608 , 0.7019608 , 0.6862745 , ..., 0.14509805,\n",
       "          0.17254902, 0.08235294],\n",
       "         [0.08627451, 0.11764706, 0.05490196, ..., 0.5137255 ,\n",
       "          0.4745098 , 0.5137255 ]],\n",
       "\n",
       "        [[0.6392157 , 0.5803922 , 0.47058824, ..., 0.41960785,\n",
       "          0.43137255, 0.39607844],\n",
       "         [0.3882353 , 0.3882353 , 0.3647059 , ..., 0.02352941,\n",
       "          0.04313726, 0.03921569],\n",
       "         [0.03529412, 0.04705882, 0.09803922, ..., 0.56078434,\n",
       "          0.52156866, 0.5647059 ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        , ..., 0.99215686,\n",
       "          0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686, ..., 0.9647059 ,\n",
       "          0.9529412 , 0.99215686],\n",
       "         [0.9882353 , 0.98039216, 0.9882353 , ..., 0.99215686,\n",
       "          0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        , ..., 1.        ,\n",
       "          1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        , ..., 0.92156863,\n",
       "          0.90588236, 1.        ],\n",
       "         [1.        , 0.9843137 , 1.        , ..., 1.        ,\n",
       "          1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        , ..., 0.99607843,\n",
       "          0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843, ..., 0.8666667 ,\n",
       "          0.84705883, 1.        ],\n",
       "         [0.99215686, 0.9764706 , 0.99215686, ..., 0.99607843,\n",
       "          0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313726, 0.47058824, 0.4392157 , ..., 0.30980393,\n",
       "          0.27058825, 0.33333334],\n",
       "         [0.3137255 , 0.27450982, 0.3372549 , ..., 0.29803923,\n",
       "          0.30588236, 0.2509804 ],\n",
       "         [0.29411766, 0.3019608 , 0.24313726, ..., 0.28235295,\n",
       "          0.3137255 , 0.30980393]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255, ..., 0.3372549 ,\n",
       "          0.30588236, 0.36862746],\n",
       "         [0.34901962, 0.29411766, 0.3529412 , ..., 0.3137255 ,\n",
       "          0.3137255 , 0.26666668],\n",
       "         [0.32156864, 0.32156864, 0.2784314 , ..., 0.30588236,\n",
       "          0.32941177, 0.32156864]],\n",
       "\n",
       "        [[0.41568628, 0.44313726, 0.4117647 , ..., 0.36078432,\n",
       "          0.30588236, 0.3647059 ],\n",
       "         [0.34509805, 0.30980393, 0.36862746, ..., 0.3372549 ,\n",
       "          0.3372549 , 0.2509804 ],\n",
       "         [0.30588236, 0.30588236, 0.2509804 , ..., 0.3137255 ,\n",
       "          0.3372549 , 0.32941177]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.13725491, 0.69803923, 0.92156863, ..., 0.94509804,\n",
       "          0.22745098, 0.7137255 ],\n",
       "         [0.9490196 , 0.23137255, 0.7137255 , ..., 0.85882354,\n",
       "          0.9607843 , 0.80784315],\n",
       "         [0.9254902 , 0.9764706 , 0.8862745 , ..., 0.34901962,\n",
       "          0.5803922 , 0.7411765 ]],\n",
       "\n",
       "        [[0.22352941, 0.7137255 , 0.91764706, ..., 0.972549  ,\n",
       "          0.2627451 , 0.7411765 ],\n",
       "         [0.96862745, 0.26666668, 0.7372549 , ..., 0.85490197,\n",
       "          0.94509804, 0.67058825],\n",
       "         [0.8352941 , 0.93333334, 0.7254902 , ..., 0.45490196,\n",
       "          0.58431375, 0.6862745 ]],\n",
       "\n",
       "        [[0.38431373, 0.77254903, 0.92941177, ..., 0.96862745,\n",
       "          0.31764707, 0.76862746],\n",
       "         [0.9764706 , 0.3254902 , 0.76862746, ..., 0.8627451 ,\n",
       "          0.93333334, 0.6313726 ],\n",
       "         [0.7921569 , 0.90588236, 0.6862745 , ..., 0.23921569,\n",
       "          0.30980393, 0.3529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627452, 0.30980393, 0.3019608 , ..., 0.29803923,\n",
       "          0.16078432, 0.23529412],\n",
       "         [0.3019608 , 0.16470589, 0.23921569, ..., 0.27450982,\n",
       "          0.36078432, 0.16470589],\n",
       "         [0.24313726, 0.33333334, 0.17254902, ..., 0.12941177,\n",
       "          0.1882353 , 0.19215687]],\n",
       "\n",
       "        [[0.23921569, 0.26666668, 0.29411766, ..., 0.30588236,\n",
       "          0.14901961, 0.22352941],\n",
       "         [0.2901961 , 0.14509805, 0.21960784, ..., 0.29803923,\n",
       "          0.3882353 , 0.19215687],\n",
       "         [0.27058825, 0.36078432, 0.18039216, ..., 0.02745098,\n",
       "          0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627452, ..., 0.28235295,\n",
       "          0.15294118, 0.22745098],\n",
       "         [0.29411766, 0.13333334, 0.20784314, ..., 0.3019608 ,\n",
       "          0.4       , 0.20392157],\n",
       "         [0.28627452, 0.3764706 , 0.18039216, ..., 0.04705882,\n",
       "          0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.7411765 , 0.827451  , 0.9411765 , ..., 0.91764706,\n",
       "          0.7019608 , 0.7921569 ],\n",
       "         [0.9137255 , 0.7058824 , 0.7921569 , ..., 0.8117647 ,\n",
       "          0.90588236, 0.73333335],\n",
       "         [0.80784315, 0.9019608 , 0.73333335, ..., 0.6627451 ,\n",
       "          0.7607843 , 0.8627451 ]],\n",
       "\n",
       "        [[0.7607843 , 0.8235294 , 0.9372549 , ..., 0.9137255 ,\n",
       "          0.7254902 , 0.79607844],\n",
       "         [0.9137255 , 0.7254902 , 0.79607844, ..., 0.8117647 ,\n",
       "          0.9019608 , 0.73333335],\n",
       "         [0.80784315, 0.8980392 , 0.73333335, ..., 0.654902  ,\n",
       "          0.74509805, 0.84705883]],\n",
       "\n",
       "        [[0.8156863 , 0.85882354, 0.95686275, ..., 0.91764706,\n",
       "          0.7764706 , 0.827451  ],\n",
       "         [0.91764706, 0.77254903, 0.8235294 , ..., 0.8235294 ,\n",
       "          0.89411765, 0.7647059 ],\n",
       "         [0.8156863 , 0.8901961 , 0.7607843 , ..., 0.6627451 ,\n",
       "          0.7490196 , 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8117647 , 0.78039217, 0.70980394, ..., 0.31764707,\n",
       "          0.28627452, 0.2627451 ],\n",
       "         [0.2       , 0.18431373, 0.16470589, ..., 0.1764706 ,\n",
       "          0.2       , 0.03921569],\n",
       "         [0.04705882, 0.04313726, 0.11764706, ..., 0.65882355,\n",
       "          0.6392157 , 0.5921569 ]],\n",
       "\n",
       "        [[0.7764706 , 0.74509805, 0.6666667 , ..., 0.        ,\n",
       "          0.01176471, 0.        ],\n",
       "         [0.        , 0.01176471, 0.        , ..., 0.15686275,\n",
       "          0.16078432, 0.31764707],\n",
       "         [0.3254902 , 0.30588236, 0.44705883, ..., 0.6862745 ,\n",
       "          0.6627451 , 0.6039216 ]],\n",
       "\n",
       "        [[0.7764706 , 0.7411765 , 0.6784314 , ..., 0.24705882,\n",
       "          0.2627451 , 0.23529412],\n",
       "         [0.22352941, 0.24705882, 0.21960784, ..., 0.5529412 ,\n",
       "          0.50980395, 0.6431373 ],\n",
       "         [0.63529414, 0.58431375, 0.6862745 , ..., 0.7647059 ,\n",
       "          0.74509805, 0.67058825]]],\n",
       "\n",
       "\n",
       "       [[[0.8980392 , 0.8980392 , 0.9372549 , ..., 0.95686275,\n",
       "          0.9098039 , 0.9098039 ],\n",
       "         [0.9490196 , 0.9098039 , 0.9098039 , ..., 0.8352941 ,\n",
       "          0.89411765, 0.83137256],\n",
       "         [0.84313726, 0.9019608 , 0.83137256, ..., 0.87058824,\n",
       "          0.8745098 , 0.9137255 ]],\n",
       "\n",
       "        [[0.87058824, 0.8666667 , 0.8980392 , ..., 0.95686275,\n",
       "          0.9019608 , 0.90588236],\n",
       "         [0.9490196 , 0.8980392 , 0.90588236, ..., 0.8392157 ,\n",
       "          0.8980392 , 0.8352941 ],\n",
       "         [0.84705883, 0.90588236, 0.84313726, ..., 0.8235294 ,\n",
       "          0.827451  , 0.8627451 ]],\n",
       "\n",
       "        [[0.8352941 , 0.80784315, 0.827451  , ..., 0.9372549 ,\n",
       "          0.88235295, 0.8901961 ],\n",
       "         [0.92941177, 0.8862745 , 0.8901961 , ..., 0.8352941 ,\n",
       "          0.89411765, 0.8392157 ],\n",
       "         [0.8509804 , 0.90588236, 0.827451  , ..., 0.7921569 ,\n",
       "          0.79607844, 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5882353 , 0.56078434, 0.5294118 , ..., 0.23921569,\n",
       "          0.39607844, 0.3764706 ],\n",
       "         [0.34901962, 0.4117647 , 0.39215687, ..., 0.65882355,\n",
       "          0.6156863 , 0.70980394],\n",
       "         [0.69411767, 0.654902  , 0.72156864, ..., 0.94509804,\n",
       "          0.94509804, 0.93333334]],\n",
       "\n",
       "        [[0.5372549 , 0.5176471 , 0.49411765, ..., 0.2509804 ,\n",
       "          0.33333334, 0.31764707],\n",
       "         [0.2901961 , 0.3764706 , 0.3647059 , ..., 0.59607846,\n",
       "          0.5529412 , 0.6392157 ],\n",
       "         [0.61960787, 0.5764706 , 0.6666667 , ..., 0.83137256,\n",
       "          0.827451  , 0.8117647 ]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705883, ..., 0.30980393,\n",
       "          0.34117648, 0.3254902 ],\n",
       "         [0.29411766, 0.27450982, 0.2627451 , ..., 0.5294118 ,\n",
       "          0.49019608, 0.57254905],\n",
       "         [0.5529412 , 0.5137255 , 0.5921569 , ..., 0.6392157 ,\n",
       "          0.6392157 , 0.6313726 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS, H, W, C = train_images.shape\n",
    "tf.reshape(train_images, [BS, C, H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS, H, W, C = train_images.shape\n",
    "BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DM_Assignment_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
