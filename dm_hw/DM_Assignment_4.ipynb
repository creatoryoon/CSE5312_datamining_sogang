{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_images = np.random.randint(256, size=(20, 32, 32, 3))\n",
    "train_labels = np.random.randint(2, size=(20,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuda 혹은 cpu를 사용하시오.\n",
    "############Write Your Code Here############\n",
    "device = 'cuda'\n",
    "############################################\n",
    "\n",
    "\n",
    "#Custom_Dataset을 정의하시오.(10점)\n",
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "#         데이터셋의 전처리를 해주는 부분\n",
    "        #입력으로 들어온 X의 pixel값들을 0-1사이로 normalize하고 X의 shape을 (FB,C,H,W)로 변경하여 저장하여 self.X,self.y에 저장하시오.\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        ############Write Your Code Here############\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.X = self.X/255\n",
    "        self.X = self.X.permute(0,3,1,2)\n",
    "        \n",
    "        self.y = torch.LongTensor(y)\n",
    "        \n",
    "#         print(self.X.shape)\n",
    "#         print(self.y)\n",
    "        ############################################\n",
    "        \n",
    "    def __len__(self):\n",
    "#          데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "        #Custom_Dataset에 저장되어있는 총 data의 개수를 result에 저장하여 반환하시오.\n",
    "        result = 0\n",
    "        ############Write Your Code Here############\n",
    "        self.len = self.y.shape[0]\n",
    "        ############################################\n",
    "        return result\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #self.X, self.y 에서 idx에 맞는 data를 result_X,result_y에 저장하여 반환하시오.\n",
    "        result_X,result_y = None,None\n",
    "        ############Write Your Code Here############\n",
    "        result_X = self.X[idx]\n",
    "        result_y = self.y[idx]\n",
    "        ############################################\n",
    "        return result_X,result_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#torch.nn을 사용하여 아래 함수들을 작성하시오. result는 nn.Layer중 하나이고 result를 반환함.(20점)\n",
    "def batch_norm(dim,for_MLP=True):\n",
    "    #for_MLP가 True일 시 MLP를 위한 BN Layer를 반환하고 False일 시 CNN을 위한 BN Layer를 반환함.\n",
    "    ############Write Your Code Here############\n",
    "    if for_MLP==True:\n",
    "        result=nn.BatchNorm1d(dim)\n",
    "    else:\n",
    "        result=nn.BatchNorm2d(dim)\n",
    "    # conv는 4차원(a, b, c, d)\n",
    "    # mlp는 3차원(a, b, c) \n",
    "    # 이기에 다른 놈을 써야한다.\n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def fc_layer(in_dim,out_dim):\n",
    "    #Fully Connected Layer(Dense Layer)\n",
    "    ############Write Your Code Here############\n",
    "    result=nn.Linear(in_dim, out_dim)\n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def conv_layer(in_ch,out_ch,kernel_size, stride=1, padding=0):\n",
    "    #Convolutional Layer for image\n",
    "    ############Write Your Code Here############\n",
    "    nn.Conv2d(in_channels=in_ch, \n",
    "          out_channels=out_ch, \n",
    "          kernel_size=kernel_size,\n",
    "          stride=stride, \n",
    "          padding=padding)\n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def relu():\n",
    "    #ReLU function\n",
    "    ############Write Your Code Here############\n",
    "    result = nn.ReLU()\n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def flatten():\n",
    "    #Flatten the data\n",
    "    ############Write Your Code Here############\n",
    "    result = nn.Flatten()\n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "\n",
    "#skip_connection(bn -> relu -> conv -> bn -> relu -> conv)를 따르는 Res_block을 만드시오.\n",
    "#change_res가 True인 res_block을 통과한 feature map은 resolution이 2배 작아지고 channel의 깊이는 2배로 증가함. ex) 32*8*8 -> 64*4*4\n",
    "#위의 경우에는 skip_connection의 dimension은 1*1 conv로 맞춰줌.\n",
    "#change_res가 False인 Res_block을 통과한 feature map은 resolution과 channel의 깊이는 그대로 유지됨. ex) 32*4*4 -> 32*4*4(20점)\n",
    "class Res_block(nn.Module):\n",
    "    def __init__(self, input_channel, change_res):\n",
    "        super(Res_block,self).__init__()\n",
    "        self.change_res = change_res\n",
    "#         if change_res:\n",
    "            ############Write Your Code Here############\n",
    "#             self.conv = conv_layer(input_channel, change_res)\n",
    "#             self.bn = batch_norm()\n",
    "            ############################################\n",
    "#         else:\n",
    "            ############Write Your Code Here############\n",
    "            \n",
    "            ############################################\n",
    "        ############Write Your Code Here############\n",
    "            \n",
    "        ############################################\n",
    "    def forward(self,X):\n",
    "        ############Write Your Code Here############\n",
    "        X = self.batch_norm(X)\n",
    "        X = self.ReLU(X)\n",
    "        X = self.conv_layer(X)\n",
    "        X = self.batch_norm(X)\n",
    "        X = self.ReLU(X)\n",
    "        X = self.conv_layer(X)\n",
    "        \n",
    "        \n",
    "        ############################################\n",
    "        return X\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Skip Connection을 이용하여 20개 이상의 layer를 가지고 테스트 셋에대하여 50% 이상의 성능을 주는 MLP를 만드시오.\n",
    "#nn.ModuleList를 사용하면 많을 층의 layer를 쌓는데 용이함.(20점)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP,self).__init__()\n",
    "        ############Write Your Code Here############\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = 5\n",
    "        self.n_layer = 20\n",
    "        self.act = relu()\n",
    "\n",
    "        self.fc = nn.Linear(self.input_dim, self.hid_dim)\n",
    "        self.linears = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.n_layer-1):\n",
    "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n",
    "    \n",
    "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
    "        ############################################\n",
    "    def forward(self,X):\n",
    "        ############Write Your Code Here############\n",
    "        X = self.act(self.fc(X))\n",
    "        for fc in self.linears:\n",
    "            X = self.act(fc(X))\n",
    "        X = self.fc2(X)\n",
    "\n",
    "        ############################################\n",
    "        return X\n",
    "        \n",
    "#Res_Block을 사용하여 테스트 셋에대한 70% 이상의 성능을 주는 CNN 모델을 만드시오.\n",
    "#flatten전에 nn.AdaptiveAvgPool2d를 사용하면 dimension맞추기가 쉬움.(20점)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channel, class_number, block_number):\n",
    "        super(CNN,self).__init__()\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "    def forward(self,X):\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        return X\n",
    "\n",
    "#loader에 있는 모든 data들에 대한 정확도를 구하여 accuracy에 저장하여 accuracy를 return하는 함수를 구현하시오.(10점)\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "    total_example = 0\n",
    "    correct_example = 0\n",
    "    for data in loader:\n",
    "        x,y = data\n",
    "        x = torch.tensor(x, device = device)\n",
    "        y = torch.tensor(y, device = device)\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "#epoch마다 train_loader에 있는 batch들을 사용하여 모델을 학습하고\n",
    "#epoch의 마지막 iteration에서는 모델의 validation accuracy를 확인하여 제일 높은 val. acc.를 가진 model을 best_model에 저장하고\n",
    "#val_acc에는 매 epoch마다 구해진 validation accuracy를 저장하시오.\n",
    "#running_loss에는 각각의 epoch에서 모든 batch의 loss를 다 더하여 저장하시오.\n",
    "#모든 epoch의 validation accuracy를 val_acc에 저장하여 best_model과 val_acc를 return하는 함수를 구현하시오.(10점)\n",
    "def train(model, epoches, train_loader, val_loader, optimizer, criteria):\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    batch_len = len(train_loader)\n",
    "    val_acc = []\n",
    "    for epoch in range(epoches):\n",
    "        running_loss = 0\n",
    "        for i,data in enumerate(train_loader):\n",
    "            x,y = data\n",
    "            x = torch.tensor(x, device = device)\n",
    "            y = torch.tensor(y, device = device)\n",
    "            ############Write Your Code Here############\n",
    "            \n",
    "            ############################################\n",
    "            \n",
    "            #epoch의 마지막 iteration\n",
    "            if i % batch_len == batch_len-1:\n",
    "                print(f'{epoch+1}th iteration loss :',running_loss/batch_len)\n",
    "                running_loss = 0\n",
    "                ############Write Your Code Here############\n",
    "                \n",
    "                ############################################\n",
    "    return best_model, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLP' object has no attribute 'out_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-72a81b6f5037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m############Write Your Code Here############\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mmlp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;31m############################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m '''\n",
      "\u001b[1;32m<ipython-input-42-9c66b6b7d704>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, output_dim)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhid_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhid_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhid_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m############################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    946\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 948\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLP' object has no attribute 'out_dim'"
     ]
    }
   ],
   "source": [
    "#(50점)\n",
    "#Read the data\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True)\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True)\n",
    "\n",
    "X_train, Y_train = trainset.data, np.array(trainset.targets)\n",
    "X_test, Y_test = testset.data, np.array(testset.targets)\n",
    "train_data = Custom_Dataset(trainset.data, trainset.targets)\n",
    "test_data = Custom_Dataset(testset.data, testset.targets)\n",
    "\n",
    "#앞서 정의한 Custom_Dataset과 DataLoader를 사용하여 train_loader,val_loader,test_loader를 정의하시오.\n",
    "#Batch_size는 본인의 컴퓨터 사향에 맞게 변경하면 됨. Validation Set으로 Train Set의 20%를 사용함.\n",
    "#Preprocessing\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None\n",
    "batch_size = 128\n",
    "############Write Your Code Here############\n",
    "val_size = int(len(train_data.y)/5)\n",
    "train_size = len(train_data.y) - val_size\n",
    "indices = list(range(len(train_data.y)))\n",
    "\n",
    "# torch.utils.data.random_split이 더 나을까?\n",
    "split = int(np.floor(.2 * len(train_data.y)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_loader = DataLoader(train_data[train_indices], batch_size=batch_size)\n",
    "val_loader = DataLoader(train_data[val_indices], batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size)\n",
    "############################################\n",
    "\n",
    "\n",
    "#앞서 정의한 MLP,CNN을 사용하여 mlp_model,cnn_model을 정의하시오.\n",
    "#Define the model\n",
    "mlp_model = None\n",
    "cnn_model = None\n",
    "############Write Your Code Here############\n",
    "mlp_model = MLP(10, 10)\n",
    "############################################\n",
    "'''\n",
    "mlp_model.to(device)\n",
    "cnn_model.to(device)\n",
    "\n",
    "\n",
    "#앞서 정의한 train함수를 사용하여 best_mlp, mpl_val_acc, best_cnn, cnn_val_acc를 구하시오.\n",
    "#Train the model\n",
    "best_mlp = None\n",
    "mlp_val_acc = None\n",
    "best_cnn = None\n",
    "cnn_val_acc = None\n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "#앞서 정의한 evaluate함수와 best_model들을 사용하여 mlp_acc, cnn_acc를 구하시오.\n",
    "#Test Accuracy\n",
    "mlp_acc = None  \n",
    "cnn_acc = None \n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "print('MLP accuracy:',mlp_acc)\n",
    "print('CNN accuracy:',cnn_acc)\n",
    "\n",
    "\n",
    "#앞서 구한 val_acc들을 사용하여 이해 가능한 그래프를 그리시오.\n",
    "#Validation Accuracy Plot\n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1492353b8b11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCustom_Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "Custom_Dataset(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
