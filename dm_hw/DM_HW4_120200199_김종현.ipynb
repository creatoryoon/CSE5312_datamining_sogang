{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DM_Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "34M35AGckhPV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Cuda 혹은 cpu를 사용하시오.\n",
        "############Write Your Code Here############\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "# print(f\"using device: {device}\")\n",
        "############################################\n",
        "\n",
        "\n",
        "#Custom_Dataset을 정의하시오.(10점)\n",
        "class Custom_Dataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        #입력으로 들어온 X의 pixel값들을 0-1사이로 normalize하고 X의 shape을 (FB,C,H,W)로 변경하여 저장하여 self.X,self.y에 저장하시오.\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        ############Write Your Code Here############\n",
        "        # 파라미터로 받은 X, y의 데이터타입을 np.float으로 변환후 \n",
        "        # 255.0으로 나눠 0-1 사이로 normalize 합니다.\n",
        "        X = X.astype(np.float64)\n",
        "        X /= 255.\n",
        "        # X의 shape을 받아서(FB, H, W, C) 알맞게(FB,C,H,W) 변환합니다.\n",
        "        (FB, H, W, C) = X.shape\n",
        "        X = X.reshape((FB,C,H,W))\n",
        "        self.FB = FB # __len__ 메서드를 위해 클래스 변수로 저장합니다.\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        ############################################\n",
        "        \n",
        "    def __len__(self):\n",
        "        #Custom_Dataset에 저장되어있는 총 data의 개수를 result에 저장하여 반환하시오.\n",
        "        result = 0\n",
        "        ############Write Your Code Here############\n",
        "        result = self.FB\n",
        "        ############################################\n",
        "        return result\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        #self.X, self.y 에서 idx에 맞는 data를 result_X,result_y에 저장하여 반환하시오.\n",
        "        result_X,result_y = None,None\n",
        "        ############Write Your Code Here############\n",
        "        result_X,result_y = self.X[idx], self.y[idx]\n",
        "        ############################################\n",
        "        return result_X,result_y\n",
        "\n",
        "\n",
        "#torch.nn을 사용하여 아래 함수들을 작성하시오. result는 nn.Layer중 하나이고 result를 반환함.(20점)\n",
        "def batch_norm(dim,for_MLP=True):\n",
        "    #for_MLP가 True일 시 MLP를 위한 BN Layer를 반환하고 False일 시 CNN을 위한 BN Layer를 반환함.\n",
        "    ############Write Your Code Here############\n",
        "    if for_MLP:\n",
        "      result = nn.BatchNorm1d(num_features=dim)\n",
        "    else:\n",
        "      result = nn.BatchNorm2d(num_features=dim)\n",
        "    ############################################\n",
        "    return result\n",
        "\n",
        "def fc_layer(in_dim,out_dim):\n",
        "    #Fully Connected Layer(Dense Layer)\n",
        "    ############Write Your Code Here############\n",
        "    result = nn.Linear(in_features=in_dim, out_features=out_dim)\n",
        "    ############################################\n",
        "    return result\n",
        "\n",
        "def conv_layer(in_ch,out_ch,kernel_size=3, stride=1, padding=1):\n",
        "    #Convolutional Layer for image\n",
        "    ############Write Your Code Here############\n",
        "    result =  nn.Conv2d(in_channels=in_ch, \n",
        "              out_channels=out_ch,\n",
        "              kernel_size=kernel_size,\n",
        "              stride=stride, \n",
        "              padding=padding)\n",
        "    ############################################\n",
        "    return result\n",
        "\n",
        "def relu():\n",
        "    #ReLU function\n",
        "    ############Write Your Code Here############\n",
        "    result = nn.ReLU()\n",
        "    ############################################\n",
        "    return result\n",
        "\n",
        "def flatten():\n",
        "    #Flatten the data\n",
        "    ############Write Your Code Here############\n",
        "    result = nn.Flatten()\n",
        "    ############################################\n",
        "    return result\n",
        "\n",
        "\n",
        "#skip_connection(bn -> relu -> conv -> bn -> relu -> conv)를 따르는 Res_block을 만드시오.\n",
        "#change_res가 True인 res_block을 통과한 feature map은 resolution이 2배 작아지고 channel의 깊이는 2배로 증가함. ex) 32*8*8 -> 64*4*4\n",
        "#위의 경우에는 skip_connection의 dimension은 1*1 conv로 맞춰줌.\n",
        "#change_res가 False인 Res_block을 통과한 feature map은 resolution과 channel의 깊이는 그대로 유지됨. ex) 32*4*4 -> 32*4*4(20점)\n",
        "class Res_block(nn.Module):\n",
        "    # https://github.com/pytorch/vision/blob/a9a8220e0bcb4ce66a733f8c03a1c2f6c68d22cb/torchvision/models/resnet.py#L101\n",
        "    def __init__(self, input_channel, change_res):\n",
        "        super(Res_block,self).__init__()\n",
        "        self.change_res = change_res\n",
        "        if change_res:\n",
        "            ############Write Your Code Here############\n",
        "            self.downsample = conv_layer(in_ch=input_channel, \n",
        "                                         out_ch=input_channel*2, \n",
        "                                         stride=2) \n",
        "            ############################################\n",
        "        else:\n",
        "            ############Write Your Code Here############\n",
        "            self.downsample = None\n",
        "            ############################################\n",
        "        ############Write Your Code Here############\n",
        "        self.bn1 = batch_norm(dim=input_channel,for_MLP=False)\n",
        "        self.relu1 = relu()\n",
        "        self.conv1 = conv_layer(in_ch=input_channel, out_ch=input_channel)\n",
        "        self.bn2 = batch_norm(dim=input_channel,for_MLP=False)\n",
        "        self.relu2 = relu()\n",
        "        self.conv2 = conv_layer(in_ch=input_channel, out_ch=input_channel)   \n",
        "        ############################################\n",
        "    def forward(self,X):\n",
        "        ############Write Your Code Here############\n",
        "        \n",
        "        identity = X.float()\n",
        "\n",
        "        X = self.conv1(X.float())\n",
        "        X = self.bn1(X)\n",
        "        X = self.relu1(X)\n",
        "\n",
        "        X = self.conv2(X)\n",
        "        X = self.bn2(X)\n",
        "        X += identity\n",
        "        X = self.relu2(X)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "          X = self.downsample(X)\n",
        "        ############################################\n",
        "        return X\n",
        "\n",
        "\n",
        "#Skip Connection을 이용하여 20개 이상의 layer를 가지고 테스트 셋에대하여 50% 이상의 성능을 주는 MLP를 만드시오.\n",
        "#nn.ModuleList를 사용하면 많을 층의 layer를 쌓는데 용이함.(20점)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP,self).__init__()\n",
        "        ############Write Your Code Here############\n",
        "        self.bn0 = batch_norm(input_dim, for_MLP=True)\n",
        "        self.linear1 = fc_layer(input_dim, 512)\n",
        "        self.linear2 = fc_layer(512, 256)\n",
        "        self.linear3 = fc_layer(256, 256)\n",
        "        self.bn3 = batch_norm(256,for_MLP=True)\n",
        "        self.linear4 = fc_layer(256, 128)\n",
        "        self.linear5 = fc_layer(128, 64)\n",
        "        self.linear6 = fc_layer(64, 64)\n",
        "        self.bn6 = batch_norm(64,for_MLP=True)\n",
        "        self.linear7 = fc_layer(64, output_dim)\n",
        "        self.relu_layer = relu()\n",
        "        ############################################\n",
        "    def forward(self, X):\n",
        "        ############Write Your Code Here############\n",
        "        X = X.view(X.size(0), -1)\n",
        "        X = self.bn0(X)\n",
        "        X = self.linear1(X)\n",
        "        X = self.relu_layer(X)\n",
        "\n",
        "        X = self.linear2(X)\n",
        "        X = self.relu_layer(X)\n",
        "        id = X \n",
        "\n",
        "        X = self.linear3(X)\n",
        "        X = self.relu_layer(X)\n",
        "        X += id\n",
        "\n",
        "        # X = self.relu_layer(X)\n",
        "        X = self.bn3(X)\n",
        "        X = self.linear4(X)\n",
        "        X = self.relu_layer(X)\n",
        "        \n",
        "        X = self.linear5(X)\n",
        "        X = self.relu_layer(X)\n",
        "\n",
        "        id = X\n",
        "        X = self.linear6(X)\n",
        "        X = self.relu_layer(X)\n",
        "\n",
        "        X += id\n",
        "        # X = self.relu_layer(X)\n",
        "        X = self.bn6(X)\n",
        "        X = self.linear7(X)\n",
        "        X = self.relu_layer(X)\n",
        "        ############################################\n",
        "        return X\n",
        "\n",
        "\n",
        "\n",
        "#Res_Block을 사용하여 테스트 셋에대한 70% 이상의 성능을 주는 CNN 모델을 만드시오.\n",
        "#flatten전에 nn.AdaptiveAvgPool2d를 사용하면 dimension맞추기가 쉬움.(20점)\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_channel, class_number, block_number):\n",
        "        super(CNN,self).__init__()\n",
        "        ############Write Your Code Here############\n",
        "        # https://dnddnjs.github.io/cifar10/2018/10/09/resnet/\n",
        "        def get_layers(in_channels, block_number, change_res):\n",
        "            layers_list = nn.ModuleList()\n",
        "            for _ in range(block_number - 1):\n",
        "                layers_list.append(Res_block(in_channels, False))\n",
        "            layers_list.append(Res_block(in_channels, change_res))\n",
        "            return nn.Sequential(*layers_list)\n",
        "\n",
        "        self.conv1 = conv_layer(in_ch=input_channel, out_ch=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = batch_norm(64, for_MLP=False)\n",
        "        self.relu1 = relu()\n",
        "  \n",
        "        self.layers1 = get_layers(64, block_number[0], True)\n",
        "        self.layers2 = get_layers(128, block_number[1], True)\n",
        "        self.layers3 = get_layers(256, block_number[2], True)\n",
        "        self.layers4 = get_layers(512, block_number[3], False)\n",
        "\n",
        "        # output layers\n",
        "        self.fc_out = fc_layer(8192, class_number)\n",
        "        \n",
        "        ############################################\n",
        "    def forward(self,X):\n",
        "        ############Write Your Code Here############\n",
        "        X = self.conv1(X)\n",
        "        X = self.bn1(X)\n",
        "        X = self.relu1(X)\n",
        "        \n",
        "        X = self.layers1(X)\n",
        "        X = self.layers2(X)\n",
        "        X = self.layers3(X)\n",
        "        X = self.layers4(X)\n",
        "\n",
        "        X = X.view(X.size(0), -1)\n",
        "        X = self.fc_out(X)\n",
        "        ############################################\n",
        "        return X\n",
        "\n",
        "\n",
        "#loader에 있는 모든 data들에 대한 정확도를 구하여 accuracy에 저장하여 accuracy를 return하는 함수를 구현하시오.(10점)\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    total_example = 0\n",
        "    correct_example = 0\n",
        "    for data in loader:\n",
        "        x,y = data\n",
        "        x = torch.tensor(x, device = device)\n",
        "        y = torch.tensor(y, device = device)\n",
        "        ############Write Your Code Here############\n",
        "        # https://becominghuman.ai/build-your-own-neural-network-for-cifar-10-using-pytorch-9bdffb389b7a\n",
        "        x = x.type(torch.float)\n",
        "        outputs = model(x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_example += y.size(0)\n",
        "        correct_example += (predicted == y).sum().item()\n",
        "        ############################################\n",
        "    ############Write Your Code Here############\n",
        "    accuracy = 100 * correct_example / total_example\n",
        "    ############################################\n",
        "    model.train()\n",
        "    return accuracy\n",
        "\n",
        "#epoch마다 train_loader에 있는 batch들을 사용하여 모델을 학습하고\n",
        "#epoch의 마지막 iteration에서는 모델의 validation accuracy를 확인하여 제일 높은 val. acc.를 가진 model을 best_model에 저장하고\n",
        "#val_acc에는 매 epoch마다 구해진 validation accuracy를 저장하시오.\n",
        "#running_loss에는 각각의 epoch에서 모든 batch의 loss를 다 더하여 저장하시오.\n",
        "#모든 epoch의 validation accuracy를 val_acc에 저장하여 best_model과 val_acc를 return하는 함수를 구현하시오.(10점)\n",
        "def train(model, epoches, train_loader, val_loader, optimizer, criteria):\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "    batch_len = len(train_loader)\n",
        "    val_acc = []\n",
        "    for epoch in range(epoches):\n",
        "        running_loss = 0\n",
        "        for i,data in enumerate(train_loader):\n",
        "            x,y = data\n",
        "            x = torch.tensor(x, device = device)\n",
        "            y = torch.tensor(y, device = device)\n",
        "            ############Write Your Code Here############\n",
        "            x = x.type(torch.float)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criteria(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            ############################################\n",
        "            \n",
        "            #epoch의 마지막 iteration\n",
        "            if i % batch_len == batch_len-1:\n",
        "                print(f'{epoch+1}th iteration loss :',running_loss/batch_len)\n",
        "                running_loss = 0\n",
        "                ############Write Your Code Here############\n",
        "                #val_acc에는 매 epoch마다 구해진 validation accuracy를 저장하시오.\n",
        "                accuracy = evaluate(model, val_loader)\n",
        "                val_acc.append(accuracy)\n",
        "                #epoch의 마지막 iteration에서는 모델의 validation accuracy를 확인하여 제일 높은 val. acc.를 가진 model을 best_model에 저장하고\n",
        "                if max(val_acc) == accuracy:\n",
        "                    best_model = model\n",
        "                ############################################\n",
        "    return best_model, val_acc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ft6yDwJ0khPi",
        "outputId": "d11fbf01-92b6-4bad-c3d2-1ea3f8cf451f"
      },
      "source": [
        "#(50점)\n",
        "#Read the data\n",
        "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True)\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True)\n",
        "\n",
        "X_train, Y_train = trainset.data, np.array(trainset.targets)\n",
        "X_test, Y_test = testset.data, np.array(testset.targets)\n",
        "\n",
        "\n",
        "#앞서 정의한 Custom_Dataset과 DataLoader를 사용하여 train_loader,val_loader,test_loader를 정의하시오.\n",
        "#Batch_size는 본인의 컴퓨터 사향에 맞게 변경하면 됨. Validation Set으로 Train Set의 20%를 사용함.\n",
        "#Preprocessing\n",
        "train_loader = None\n",
        "val_loader = None\n",
        "test_loader = None\n",
        "batch_size = 1\n",
        "############Write Your Code Here############\n",
        "batch_size = 128\n",
        "test_dataset = Custom_Dataset(X_test, Y_test)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "train_val_dataset = Custom_Dataset(X_train, Y_train)\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(train_val_dataset, [40000, 10000])\n",
        "val_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "############################################\n",
        "\n",
        "\n",
        "#앞서 정의한 MLP,CNN을 사용하여 mlp_model,cnn_model을 정의하시오.\n",
        "#Define the model\n",
        "mlp_model = None\n",
        "cnn_model = None\n",
        "############Write Your Code Here############\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "mlp_model = MLP(3*32*32, 10)\n",
        "cnn_model = CNN(input_channel=3, class_number=10, block_number=[2, 2, 2, 2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=0.02, momentum=0.9)\n",
        "cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "############################################\n",
        "mlp_model.to(device)\n",
        "cnn_model.to(device)\n",
        "\n",
        "\n",
        "#앞서 정의한 train함수를 사용하여 best_mlp, mpl_val_acc, best_cnn, cnn_val_acc를 구하시오.\n",
        "#Train the model\n",
        "best_mlp = None\n",
        "mlp_val_acc = None\n",
        "best_cnn = None\n",
        "cnn_val_acc = None\n",
        "############Write Your Code Here############\n",
        "epoches = 60\n",
        "best_cnn, cnn_val_acc = train(cnn_model, epoches, train_loader, val_loader, cnn_optimizer, criterion)\n",
        "best_mlp, mlp_val_acc = train(mlp_model, epoches, train_loader, val_loader, mlp_optimizer, criterion)\n",
        "############################################\n",
        "\n",
        "\n",
        "#앞서 정의한 evaluate함수와 best_model들을 사용하여 mlp_acc, cnn_acc를 구하시오.\n",
        "#Test Accuracy\n",
        "mlp_acc = None  \n",
        "cnn_acc = None \n",
        "############Write Your Code Here############\n",
        "mlp_acc = evaluate(best_mlp, test_loader)\n",
        "cnn_acc = evaluate(best_cnn, test_loader)\n",
        "############################################\n",
        "print('MLP accuracy:',mlp_acc)\n",
        "print('CNN accuracy:',cnn_acc)\n",
        "\n",
        "\n",
        "#앞서 구한 val_acc들을 사용하여 이해 가능한 그래프를 그리시오.\n",
        "#Validation Accuracy Plot\n",
        "############Write Your Code Here############\n",
        "plt.plot(mlp_val_acc)\n",
        "plt.plot(cnn_val_acc)\n",
        "plt.legend(['mlp_val_acc', 'cnn_val_acc'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy Plot')\n",
        "plt.show()\n",
        "############################################"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "1th iteration loss : 1.7741016008602544\n",
            "2th iteration loss : 1.3786145136379206\n",
            "3th iteration loss : 1.1387192159415054\n",
            "4th iteration loss : 0.9116287475195937\n",
            "5th iteration loss : 0.6979503514477239\n",
            "6th iteration loss : 0.47212459575444365\n",
            "7th iteration loss : 0.33351051312285107\n",
            "8th iteration loss : 0.2560688198184053\n",
            "9th iteration loss : 0.1612540849576743\n",
            "10th iteration loss : 0.09254311538709048\n",
            "11th iteration loss : 0.03733560079768205\n",
            "12th iteration loss : 0.00930734690890228\n",
            "13th iteration loss : 0.0017217169456279127\n",
            "14th iteration loss : 0.0006998907573842488\n",
            "15th iteration loss : 0.0004833472621874116\n",
            "16th iteration loss : 0.0003910604032621639\n",
            "17th iteration loss : 0.0003427403855149429\n",
            "18th iteration loss : 0.0002909112649061494\n",
            "19th iteration loss : 0.0002692327266536689\n",
            "20th iteration loss : 0.00025082542737663244\n",
            "21th iteration loss : 0.00022298155153302636\n",
            "22th iteration loss : 0.00021033066798826477\n",
            "23th iteration loss : 0.00020265785988681347\n",
            "24th iteration loss : 0.00018127650300899266\n",
            "25th iteration loss : 0.00017854103251987438\n",
            "26th iteration loss : 0.000163723486258995\n",
            "27th iteration loss : 0.00015546863406938247\n",
            "28th iteration loss : 0.0001479555431635494\n",
            "29th iteration loss : 0.0001443197748063284\n",
            "30th iteration loss : 0.00013615832259687342\n",
            "31th iteration loss : 0.00013037331346697664\n",
            "32th iteration loss : 0.0001267148061614921\n",
            "33th iteration loss : 0.0001231745260540015\n",
            "34th iteration loss : 0.00011935367102689369\n",
            "35th iteration loss : 0.00010997693470200173\n",
            "36th iteration loss : 0.00011021004248292933\n",
            "37th iteration loss : 0.00010531925988780073\n",
            "38th iteration loss : 0.00010079703049984546\n",
            "39th iteration loss : 9.955625783316582e-05\n",
            "40th iteration loss : 9.95049625528216e-05\n",
            "41th iteration loss : 9.558503033434109e-05\n",
            "42th iteration loss : 9.228492794886079e-05\n",
            "43th iteration loss : 9.011341387758584e-05\n",
            "44th iteration loss : 8.843725070840093e-05\n",
            "45th iteration loss : 8.574888983647675e-05\n",
            "46th iteration loss : 8.245359448790059e-05\n",
            "47th iteration loss : 8.511780771178033e-05\n",
            "48th iteration loss : 8.004186767471074e-05\n",
            "49th iteration loss : 7.815261297697832e-05\n",
            "50th iteration loss : 7.828002251484194e-05\n",
            "51th iteration loss : 7.3636804365913e-05\n",
            "52th iteration loss : 7.442897233337286e-05\n",
            "53th iteration loss : 7.348513185723905e-05\n",
            "54th iteration loss : 7.148127883956128e-05\n",
            "55th iteration loss : 6.725805763790485e-05\n",
            "56th iteration loss : 6.676767161218285e-05\n",
            "57th iteration loss : 6.687460896477606e-05\n",
            "58th iteration loss : 6.49608248404373e-05\n",
            "59th iteration loss : 6.336244766720564e-05\n",
            "60th iteration loss : 6.571603760315914e-05\n",
            "1th iteration loss : 1.7211906319609085\n",
            "2th iteration loss : 1.4725968163615217\n",
            "3th iteration loss : 1.3518435955047607\n",
            "4th iteration loss : 1.264014141818586\n",
            "5th iteration loss : 1.1855969213830015\n",
            "6th iteration loss : 1.1170630885389286\n",
            "7th iteration loss : 1.0526148450260344\n",
            "8th iteration loss : 1.0010770174641959\n",
            "9th iteration loss : 0.9418222892779512\n",
            "10th iteration loss : 0.8880309780565695\n",
            "11th iteration loss : 0.8309097000585196\n",
            "12th iteration loss : 0.7815491488566414\n",
            "13th iteration loss : 0.7248832670073159\n",
            "14th iteration loss : 0.6846567169545938\n",
            "15th iteration loss : 0.645768348496562\n",
            "16th iteration loss : 0.6035867880898923\n",
            "17th iteration loss : 0.5527162902271405\n",
            "18th iteration loss : 0.5194369631643874\n",
            "19th iteration loss : 0.48225504178970385\n",
            "20th iteration loss : 0.4467122784723489\n",
            "21th iteration loss : 0.41369117615512385\n",
            "22th iteration loss : 0.3848837735458685\n",
            "23th iteration loss : 0.3579329188448933\n",
            "24th iteration loss : 0.34172340370595644\n",
            "25th iteration loss : 0.31332790097013447\n",
            "26th iteration loss : 0.29250144330076516\n",
            "27th iteration loss : 0.2747668963366042\n",
            "28th iteration loss : 0.2550700710842404\n",
            "29th iteration loss : 0.2467610097874087\n",
            "30th iteration loss : 0.22228097984680353\n",
            "31th iteration loss : 0.21243846903260524\n",
            "32th iteration loss : 0.19664623826361313\n",
            "33th iteration loss : 0.18642566591120377\n",
            "34th iteration loss : 0.18644681213477168\n",
            "35th iteration loss : 0.1702258896570617\n",
            "36th iteration loss : 0.1516998914150765\n",
            "37th iteration loss : 0.15812186801585906\n",
            "38th iteration loss : 0.12944070788951348\n",
            "39th iteration loss : 0.1354960052016825\n",
            "40th iteration loss : 0.12979319326270122\n",
            "41th iteration loss : 0.13639923039907084\n",
            "42th iteration loss : 0.11728302375101053\n",
            "43th iteration loss : 0.10870768042941825\n",
            "44th iteration loss : 0.1012046718464111\n",
            "45th iteration loss : 0.10916896621449687\n",
            "46th iteration loss : 0.10302349746215363\n",
            "47th iteration loss : 0.09513983607720643\n",
            "48th iteration loss : 0.08711773550179534\n",
            "49th iteration loss : 0.0888704664695758\n",
            "50th iteration loss : 0.0801822880086617\n",
            "51th iteration loss : 0.0921787495662372\n",
            "52th iteration loss : 0.09237696064975315\n",
            "53th iteration loss : 0.0819868364463599\n",
            "54th iteration loss : 0.07761296008627255\n",
            "55th iteration loss : 0.0737885612631425\n",
            "56th iteration loss : 0.06371091809064246\n",
            "57th iteration loss : 0.06890862004849287\n",
            "58th iteration loss : 0.06417058328368937\n",
            "59th iteration loss : 0.06799825245496659\n",
            "60th iteration loss : 0.05891888800520485\n",
            "MLP accuracy: 54.08\n",
            "CNN accuracy: 56.79\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e+b3gkJCZBACIFAKKEGREAEEUGwIoJddFcX+7q2Vdd1dX+6q1vctYuuXRQsqIgiYAVRqaF3CCUJJKSH9Mz5/XEnIYFJMgmZhDDv53nyTObWM+2957733HPEGINSSin34dHaBVBKKdWyNPArpZSb0cCvlFJuRgO/Ukq5GQ38SinlZjTwK6WUm9HAr1xKRIyI9LT//7KIPOLMsk3Yz9Uisrip5VT1E5G/iMi7rV0O1Tw08Kt6icgiEXncwfSLReSQiHg5uy1jzCxjzF+boUyx9oNE9b6NMe8ZY8472W3Xs8/uImITkZdctY/WJiJvikiZiBSKSLaILBGRhCZsJ0VEznVFGVXz0MCvGvIWcI2IyHHTrwXeM8ZUtEKZWsN1QA4wQ0R8W3LHIuLZgrt72hgTBHQBMoA3W3DfqoVo4FcN+RQIB86qmiAi7YELgLdFZLiI/CwiuSKSLiLPi4iPow3Za5T/V+P5ffZ10kTkxuOWnSIi60QkX0QOiMhfasz+0f6Ya6+dnikiM0VkeY31R4rIKhHJsz+OrDHvexH5q4j8JCIFIrJYRDrU9QbYD3rXAX8CyoELj5t/sYgk28u6W0Qm2aeHicgb9teXIyKf2qfXKqt9Ws2U2Jsi8pKIfCkiR4FxDbwfiMhoEVlh/xwO2PcxTEQO1zxwiMhUEVlf12utYowpAuYA/et4Ty4Skc32/X0vIn3s098BYoAF9s/m/ob2pVqeBn5VL2NMMTAPK/BVmQ5sM8asByqBu4EOwJnAeODWhrZrD473AhOAeOD41MBR+z5DgSnALSJyiX3eGPtjqDEmyBjz83HbDgMWAs9iHbT+DSwUkfAai10F3ABEAj72stRlNFYN+AOs9+L6GvsaDrwN3Gcv6xggxT77HSAA6GffzzP17ON4VwFPAMHAcup5P0SkG/AV8BwQAQwCko0xq4AsoGYK7Fp7eeslIkHA1cA6B/N6Ae8Dv7fv70usQO9jjLkW2A9caP9snm7Ea1YtRAO/csZbwDQR8bM/v84+DWPMGmPML8aYCmNMCvAKcLYT25wOvGGM2WSMOQr8peZMY8z3xpiNxhibMWYDVqBxZrtgBcadxph37OV6H9hG7Zr6G8aYHTUObIPq2d71wFfGmBysWvAkEYm0z/sN8LoxZom9rKnGmG0i0hk4H5hljMkxxpQbY35wsvwAnxljfrJvs6SB9+MqYKkx5n37frKMMcn2eW8B10D1AXGi/TXU5V4RyQV2AUHATAfLzAAW2l9zOfBPwB8Y6WBZdQrSwK8aZIxZDhwBLhGRHsBw7MFDRHqJyBf2C735wJNYtf+GRAEHajzfV3OmiJwhIt+JSKaI5AGznNxu1bb3HTdtHxBd4/mhGv8XYQW5E4iIP3A58B6A/exiP1awBegK7Hawalcg236waIqa701D70ddZQB4F7hQRAKxDrbLjDHp9ez3n8aYUGNMJ2PMRcYYR9ut9f4aY2z28kY7WFadgjTwK2e9jVXTvwb42hhz2D79JazadLwxJgR4CDj+QrAj6VgBq0rMcfPnAJ8DXY0x7YCXa2y3oS5l04Bux02LAVKdKNfxLgVCgBftB7dDWAGuKt1zAOjhYL0DQJiIhDqYdxQrBQSAiHRysMzxr7G+96OuMmCMSQV+BqZipXnecbRcI9V6f+3XQLpy7P3VLn9PcRr4lbPexsrD34Q9zWMXDOQDhfamf7c4ub15wEwR6SsiAcCjx80Pxqoxl9jz6FfVmJcJ2IC4Orb9JdBLRK4SES8RmQH0Bb5wsmw1XQ+8DiRipYMGAaOAgSKSCPwPuEFExouIh4hEi0iCvVb9FdYBo72IeItI1bWJ9UA/ERlkT5/9xYly1Pd+vAecKyLT7a83XERqpq7eBu63v4ZPmvAeHG8eMMX+mr2Be4BSYIV9/mHq/mzUKUADv3KKPX+/AgjEqnlWuRcrCBUArwJzndzeV8B/gG+x8snfHrfIrcDjIlIA/Bkr2FStW4R14fMne6uSEcdtOwur1dE9WBc37wcuMMYccaZsVUQkGuti9X+MMYdq/K0BFgHXG2NWYl0kfgbIA37gWG34WqxWQNuwmkb+3l6+HcDjwFJgJ9bF24bU937sBybbX282kAwMrLHufHuZ5tvfu5NijNmOdeb3HFYK8EKsi7ll9kX+BvzJ/tnUd9FctRLRgViUOv2JyG7gd8aYpa1dFtX6tMav1GlORC7Dyrsff1al3JTTt9srpdoeEfke6/rGtfbWN0ppqkcppdyNpnqUUsrNtIlUT4cOHUxsbGxrF0MppdqUNWvWHDHGRBw/vU0E/tjYWFavXt3axVBKqTZFRI6/gx3QVI9SSrkdDfxKKeVmNPArpZSb0cCvlFJuRgO/Ukq5GQ38SinlZjTwK6WUm9HAr5Q7y0mBbQsh90CDi55WDm2E1W9ARVnDy56G2sQNXEqdsmyVsOc72DAPOiXCyDtOcns2KD8KJflQkgf5aZB3APJTIe8gFKRD1BAYdBV0iG/89o2BjC2w9QvYtsAKgFVCoqHrGRAzwnqM7ANevif3elqaMSD1DABXkgffPgGrXgVjg1WvwSUvQueBda9zGmoTnbQlJSUZvXPXxYyB3P1w4FcrMET2g+5nQbCjUQHtirLB0wd8HQ5X63gfR3bAnh9g7w9WbbNLEnQfA7FjIOiEO8td4+AaWP8+lORaAbY033osPwoe3law8/IFT1/w9oOwOCsIRvazHv1DIXMHrJ8D6z+wgrGXH1SUwNiHYOwDzpelJB9+fgE2fABFOVZZHI1cKJ4Q3BkCwuDwJitodRluHQD6TwW/dtbnkbUbsndbj0VHoKLU+qu0P2btguw9gFjBvc8FED3UOgDs/8X6/PNTj+0zvKf9tfeFjn2hxzngE9i0972yHI4egaOZ9r8jUJxjvW81yyge0Oci67tRVxA3BtLWwqFNx15v9h7I3guBHSBhCvS5EGLOBA9Pa/kN82Dxn6x9D/sNdBsJix60ynHWH2DMfbUPdGVFkLLMel/C4qwDYnjP+g8stV5vBWz6yPp+9BhvVQyOX7eyAlJ+hE0fW69h3MPW766ZiMgaY0zSCdM18LupsiIrgKSuOfaDL6gag1uoDj4RCVZg7jbKCkoZW60Dw+EtcDTDWiaoI4T1gPA469G/PVSW2X/Q9sfc/bD3Ryi0j3HeLgbCe1j7L823pkX2g9hREBQJvu3ALwR8g62gFpFg/aBPRnkJfPcE/Pw8eAdAYIR9HyHWPrwDwFZ+rMyVZVBWaP0gq8oIENDBCqriCfETrOAbfx4svAeS34Nxf4Kz72v4/V85G376jxX8ep5rvXfV5bGXKTgK2kVDUCfwtJ+gFxyygljye5C5zTroePlZB7Iq4mF9Dl7+4OVjHcS8fK3Pqvck6D0Fgjs6LlvuATi4yvqcM7bC4c3WQRoDAeHWWc2w31qfTUPKimDzfFjzJhxcWf+yHl5WOW3l1nvfsT8MnQkDZljvhzHWAWrTx7DpE8jbb1/PG8K6W+9fWBzk7IXd31qfYUA49D4fslNg33LrIDflXxA12Fq3KBu+fsiqCET2hQmPW5/3zsWQstw6GNX8PQSEWwfMrmdA3FjoNAA8jsuY22yw+RP4/m/WgbZKUCeIP9f6rgR0gC2fWu/N0UzwCbZeY34anHUPjP0jeHo3/P42QAO/uyvKtn4wacmQts4KGKbSmteua+1T/IgEyNhsBeo9P8D+n6HcPmKflz9EJthrvwnWDzRrz7FaV9XBoCbxsIJs7GjofrZ1IGkfa9V+KisgPdk6A9jzgxVwyusYHbBdV+uUPGowRA2yfqjBnZ2rgR1YCZ/dZp1xDJ0JE/5q/dCcYYyVZqk66B3ZYb1HA2bUDp62Svj0Vqv2fs4jMMbBqINlRbDuXVj2Tyg8bAX8c/50LBA1hjHWZ7lhnhWgwnpYB9OwHtC+W/OmacqOwsHVsOJZ2LXUOqiMuA3OuNk6QB0vYxusecN+ZpUHHXpB34utzyswwjq4B0bYD05+Vlk9PK11Swtg44dWDv7QBvAOtA5WhzZa7714Wmce/S+Dbmda34uqdauUFlrl3PYF7Pjamj/+URhy/YmBGqxlFtx1rPITHm8d1OMnWGcNufuPVZD2/2J938E6kPacYAX0uHGw7ycrlZSx2fqNnPMwRCfB7m+sg8mub6E0z1rXyw96TYT+06yDga0CvnoAkt+FLsPgstes38lJ0MDvzoqy4c0pVtAKCLcHzsHQeZD12C66/vUryqwfXUB7CI11/MOpUpJv1ZK9/Kw0kJffsZqqsypKj6VgSvOt8mdssYJc2jp7qsLOO8Cq5YXFWUEvOOrYmUJVzXnDPCud0q4LXPSsFTRcxVYJ82fBxnlw7l9g9N1WjX7H17B1Aez6BiqKodtoK+B3O9N1ZXGV1DXwwz9gx1fWmVlkgj1VU3YsbZOfatXE+14MSTdYZ4zOpkiqVKVzVr8BWz+HjolWWqvvJRAY7vx2KsqsfTdUgy7Otc4UogZZ36f6FBy2lt252ArqJXnH5oX1gHEPQb+pJ/5WKiusM5/CDOg53vFZ06aPYcHdgIEp/4YBlzv1Mh3RwO+uSgvh7YutmtMVc6waZmN/gKea4lxIX2/V/rL3WH9Zu610hK3c8TpJN1qn8c6kJ06WrRI+udnK70YPtcpqq7BquwlTrIDQbWTb/xzSN8CK56wzl5rXRbx8rTOiQVedfHquLaisgNTV1oEgtJt1JtjYys7xcvZZ36EDv8C0N6wDXhNo4HdH5SUwZ7qVq5z+lnWx63RWWWG/YJtnpQuqLtqGREH0kJYvy4I7rfRI7/Ot9z5qSP1nS0rVVFkBa9+CIdc1Od9fV+DX5pynq8oK+OhGK3d+ycunf9AHq5YV2OHUqGV6elnNBJVqKk8vq/WRC2j143Rks1kXMrcvhPOfhkFXtnaJlFKnEA38pxtj4Kv7rJYl4x6GM37X2iVSSp1iNPCfToyxmoOtes1qaz2mgbbkSim3pIH/dGGMdRfiyles9tUT/tr2W40opVxCA//pwBjrVvRfX4IzboGJT2jQV0rVyaWBX0RSRGSjiCSLyOoa0+8QkW0isllEnnZlGU57xsCSR6xuCIb/Dib9TYO+UqpeLdGcc5wx5kjVExEZB1wMDDTGlIpIZAuU4fT1w9PWTTTDboLzn9Kgr5RqUGukem4B/m6MKQUwxjjo3EU5xRgrvdN7Mkz+hwZ9pZRTXB34DbBYRNaIyM32ab2As0TkVxH5QUSGOVpRRG4WkdUisjozM9PFxWyjcvdb/cDET9Cgr5RymqtTPaONMan2dM4SEdlm32cYMAIYBswTkThzXN8RxpjZwGywumxwcTnbpvT11qObDSKhlDo5Lq3xG2NS7Y8ZwHxgOHAQ+MRYVgI24BS4x74NSk+2+jCP7NfaJVFKtSEuC/wiEigiwVX/A+cBm4BPgXH26b0AH+BIXdtR9UhfDxF9rFGilFLKSa5M9XQE5ouVe/YC5hhjFomID/C6iGwCyoDrj0/zKCcYYw2q0mtSa5dEKdXGuCzwG2P2ACckn40xZcA1rtqv28hPs4b/ixrU2iVRSrUxeuduW5WebD3qhV2lVCNp4G+r0tdbY9l27N/aJVFKtTEa+NuqtGTo0Bt8Alq7JEqpNkYDf1uVvl7z+0qpJtHA3xYVHILCQ5rfV0o1iQb+tkjv2FVKnQQN/G1RWjIg0CmxtUuilGqDNPC3RenrIbwn+Aa3dkmUUm2QBv62KD1ZL+wqpZpMA39bU5gJ+ama31dKNZkG/ram+sKu1viVUk2jgb+tqe6qYUDrlkMp1WZp4G9r0pMhLA782rV2SZRSbZQG/rYmfb1L8/tFZRX89YstZBaUumwfSrmzH3Zk8vevtlFYWtFqZdDA35YUZVvj7Lowv//FhnT+t3wvL3y3q97ljDHc/PZq/rd8r8vKotTp5oOV+7nhjZW8/MNupjy7jOQDua1SDg38bUkL3LH75cZ0AD5YtZ/so2V1Lrd4y2EWbznMqz/uodKm4+goVR9jDP9dupM/frKR0fERvHXjcCoqDdNeWsGL3+9q8d+QBv62xMnA//XmQ7z7y75Gbz6vqJyfdh3h3D6RlJTbeHNFisPlbDbDf5buxMfTg0P5Jfy6N6vR+1LKXVRU2nho/kaeWbqDy4Z04X/XJ3F2rwi+vPMsJvbrxNOLtnPNa79yKK+kxcqkgb8tSU+G0BgICKtzkZQjR7nz/XU88tkm1jfyNHLJ1sOUVxpuPyee8/p25K0VKRx1kIdcvOUwW9PzefSivgT4ePJ5clqjX4pS7qC4rJJZ767h/ZUHuG1cD/55+QC8Pa2w2y7Am+evGsxTlyWSfCCXc//9A7PeWcPbP6ewK6MQV45Iq4G/LWngwq4xhgc/2YiPpwfhgb48+vlmbI04hfxyYzrRof4M7NKOWWN7kFdczvsr99daxqrt76B7h0BmJHVlYr9OfLkxndKKyia/rCqZBaV8tOZgs2xLnRxHB3zVOMYYbn1vDd9sy+Dxi/tx38QE7GOQVxMRZgyL4Ys7RzM5sRMbU/P482ebOfffP3DGk9/w+w/WsSUtv9nLpoG/rSgthOw90KnuwD9v9QF+3pPFg5P78MfzE0g+kMvHaw86tfn8knKW7cxkcmInRIQhMe0ZERfGa8v2UlZhq17u682H2HaogDvH98TL04OLB0WRX1LB99szm/zSDueX8NiCzYx+6lvu/XA9/168o8nbUidv7f4cBjy2mL99tbVRFQdV2/srD/Dd9kz+fEFfrjsztt5le0QE8fS0gSx/YBw/3DeWv01NZHj3MJbtPOKSipDLBltXzezIdusxso/D2Rn5JTyxcCtndA/jimFdAXjv1308tWg7E/t3IsTPu97NL91ipXnOT+xcPe2WsT25/vWVfJqcyvSkrthshv9+s5O4DoFcNDAagNE9OxAe6MNnyalM7NepUS8pNbeYl7/fzdzVB6i0GS4dHE1phY1Xl+1hYv9ODIlp36jtqebx8ZqDVNoMr/ywh4z8Up66bAA+XlpHbIz9WUX838ItjOoZzvUNBP2aRIRu4YF0Cw/kyuExGGNwRcbHpYFfRFKAAqASqDDGJNWYdw/wTyDCGHPEleU4LWTaA39EgsPZj36+mZIKG3+bmoiHh3U6+dhF/bj4hZ94dulO/nRB33o3/+XGQ0S182Nw19DqaWPiO9C3cwgv/7CbaUO6sMhe2//PjEF42vfh5enBBQM68/6qAxSUlBPcwAGmyju/7OPxBZsBmDa0C7ec3ZOY8AAKSspZuy+Hez9cz5d3noWft2cd5U0nNMCbM+PCTzh9Vk1XXmnjq02HuGBAZxI6BfPPxTs4UljKS9cMJcj39KknfpacypNfbiXU34fwIB86BPkSHuRDt7AArjqj20kd6Gw2w70frcdDhKenDaz+PTaFiOCKr3dLHMbHGWMGHRf0uwLnAfvrXk3VkrEVPH2gfewJsxZtOsRXmw5x1/h44iKCqqcP6BLKjKSuvLkihV0ZBXVuuqCknB93ZjKpf+daQVREuGVsD/ZkHuXrzYf479KdxEUEcuHAqFrrXzw4mrIKG4s2HXLqpbz0/W4e+XQTZ8VH8P194/jb1AHEhFtjBwf7efP3yxLZk3mUZ5acmPIxxvC3L7dy63truerVXzn/v8v4YOV+Ssr1ukBzWLE7i+yjZVw0MIrbz4nn6WkDWLE7ixmv/ExGQcu1OqmprMLGyr3ZbDyYR1Zh6Ulf9LTZDM8s2YGPlwfdwgMorbCx4WAuH60+yF8WbOG2OWtrpTcb640VKazcm82fL+xLdKj/SZXVVVrrEP4McD/wWSvtv+3J3A7h8eBZ+yPLKy7nz59tok/nEG4eE3fCavdN7M3Cjek8tmALb9843GHt+JutGZRV2Jgy4MRUzfn9O9EtPIAHPt5AfkkF/73iWG2/yuCuocSEBfBZchqXJ3Wt8yUYY/j3kh089+0uLhoYxb+mD6xu4VDTWfERXDk85oSUT1WzuHmrD3LNiBgGRIfy+k97+eMnG3lq0TauHB7D9SNj6RjiV28Z3vgphTX7cvjvFYPwcrB/d7ZgfRrBfl6c3TsCgOlJXYkI9uXWd9cy9cUVfHDzCLq0D2iWfR0pLOXn3VnEhAUQ3zGIAJ9j3+1Km+HXvVksWJ/GV5sOkVtUXj3P18uDqFB/okL9mDa0C5cMim7UWd832zJIySri+asGc8GA2pWYt1ak8Ojnm7nj/bU8f9UQh9/P+uzKKOTpRds4t08klw/t0qh1W5KrA78BFouIAV4xxswWkYuBVGPM+vo+LBG5GbgZICYmxsXFPPXYbKb2KWLmNuiSdMJyTy7cypHCUl67PsnhlzQ8yJc/TOjFYwu2sHjLYYd5+C83ptMpxI/BXU/MqXt5enDzmDgenr+JnpFBJ/xQwDozuHhQFC98t4uM/BIiHQReYwx//WIrr/+0lyuGdeWJSxNPOIDU9NDkBH7ckVmd8gG464N1fL35MHeOj+fuc+MRES5P6sIve7J546e9vPzDbt5akcL9kxK4ZkS3E7afV1TOPR+uZ+nWwwDcMrYH/aNbvs+jSpup97W3ltKKSr7efIjz+nbC1+tYim1c70g+uHkEV8z+hWe/2cnT007+BsKvNx/iwU82Vt8kKAIxYQH06hhMeKAP327LIKOglAAfT87r29F+NgppucWk55WQmlvM9kMF3D13PV9vOsyTUxMJC/Rxat+vLdtDdKg/kxz8Fq4fGYvNGB5bsIU731/Hs1cOdjr4V1TauOfD9fj7ePLk1MRTOgXp6sA/2hiTKiKRwBIR2QY8hJXmqZcxZjYwGyApKcmtmhbsPFzAjNm/cNf4eK4fGQtlR62uGgZfU2u5easPMHf1AW4Z24MBXUIdbwy4dkQ3Plh5gEc/20zX9gH0jQqpnldYWsH3OzK5anhMnbnIy4Z0YemWw8wc1b3OgHXxoCie+3YXCzak85vR3WvNq7QZHp6/kQ9WHeCGUbH8+YK+Df4oqlI+1/5vJU8s3MqujEJ+3pPFoxf25YZRx7YvIpzZI5wze4STcuQoj3y2iUc/38z8dan8/bJEEjpZr3Xd/hxun7OOjIISfjcmjld+3EPygdxmC/wrdh/B39uTwfVckD5aWsH9H2/gp11H+Pf0gZyT0LFZ9t1cftxxhIKSCi4c2PmEeQO7hjJ1SDQfrjnIH8/v43SQPV5BSTmPLdjCR2sO0i8qhBeuGkJecRnbDxWy43AB2w8X8PPuLEb1DOeigdGckxCJv4/j6zyVNsOry/bwr8XbOe+ZHJ6eltjge7rxYB6/7s3mT1P61Hm2d8Oo7tgM/PWLLfz+g2SHZ4aVNkNOURlHCkvJKrQeV+zKYv2BXJ6/ajCRwXWfdZ4KXBr4jTGp9scMEZkPnA10B6pq+12AtSIy3BjjXILYDTz99Xayj5bxlwWbiQj2ZXL4IcBARO/qZdbtz+FP8zcxumcH7pnQq97teXl68K/pA7nxzVVc8uJP/OXCflw5vCsiwrfbrDTP5MQTf+xV/Lw9eeOG4fXuo2dkMP2iQvg8ObVW4P91Txb/+Ho7q/flcMc5PfnDhF5O14SqUj7v/LIPTw/hPzMGccng6DqXj+0QyNs3Duez5DQe/2ILFzy7nN+dHUf7AB+eWrSNyGA/Ppw1koFd2vHRmoOs25/LNSO6OVWW+ny6LpU/zEvGADedFccfJvQ64aL0/qwibn5nNTsOF9A1LIAb31zNnef05K5ze7mk9l9eaWPH4QLSc0tIyysmLbeEtNxiwoN8eGRKX4cH+QXr02gf4M2onh0cbnPmyFje+3U/76/cz23jeta575LySvKKywn288Lf27P68/51TxZ/mLee9Lxibh/XkzvHx1dfRJ3Uv/Gv0dNDmHV2D8bER/CHecnc+OZqrhwew5+m9CGwjgvR/1u+h0AfT6YPqzslCfCb0d0xxvB/C7diM4Yze4Sz98hRUo4cZV9WEfuzi6hw0NR1elIXh2fFpxqXBX4RCQQ8jDEF9v/PAx43xkTWWCYFSNJWPces2ZfNki2HueOcnqzYncXv5ybT++xUegBEWE05M/JLmPXuGjq28+W5Kwc7lafuH92OL+86i7vnJvPQ/I38sieLJ6cm8uWGdCKDfUnqdvJNJy8ZFM0TX25l75Gj5BeX88/F21m28wiRwb48fdmABn9sjjw0OYGisgouGRzNuN6RDS4vIlwyOJoxvSJ4YuFWXvhuNwAT+nbkn9MG0i7AanU0qGsoyQdyGtzez7uz6BsVQjt/x62VPku2gv7w7mHERQQx+8c9/LA9k2dmDKo+s1q+8wi3zVkLwFs3DmdYbBh/+nQTz367i3UHcnn2isG0d7IGvWZfNgmdQuoMbGCl1W56e3Wteyu8PYUOQb6k55XQLSyAmaNqn5UVlVWwZMthLh0SXWdqI75jMKN7duDdX/bxuzFxDr93lTbDjFd+Zv3BPMAKzsF+XgT7eXEwp5huYQF8OGskQ5vh+1alb1QIn90+in8v3sHsZXvYnJbH+zeNOOE9OpRXwhcb0rnuzNgGmzcD/PasOGzG8OSX2/hq0yECfDzpFh5IQudgJvbvROd2flZroEAfwoN86RDkU+f35FTjyhp/R2C+/WjvBcwxxixy4f7aPGMMT321nYhgX24Z24MbR3Vn2ssr+O6nZcR5eCNh3SmtsG4Bzy+uYP5tI50OGAAdgnx564bhvPj9Lv69ZAcbU/NIzytmelLXk2pyVuXCgVE8+dVWrnv9Vw5kFxMW6MPDk/tw7Znd6myW2ZBgP2/+e8XgRq8XFujDv6YPZNrQLqTnFXPp4NoXAAfHhPLNtgzyisvr/LFuSs3jyld/oUOQDw+e34epQ2pvY8H6NO6em8yw2DBenzmMAB8vJvTpyP0fb+DiF5Zz94Re+Hh68OSXW4mPDGb2dUPpFh4IwD+mDWBITHv+8vlmLnhuOS9dM6TedB3Awvm4/1AAACAASURBVA3p3DZnLVMSO/PC1UPqXO7HnUf4fnsmvxsTx/mJnYkK9aNDoC8icMObq/j7om2M6RVRqwXYt9syKC6v5MIGaqvXj4zlprdXs3jLYYdniXNW7mf9wTxuHhNHWKAPBSXlFJRUWCmkAX7cNq5nvQetpvL18uTByX0Y2q09s95dw21z1vLqdbWve731cwo2Y7hhVKzT2715TA8m9euMr7cHkcG+p3TevjFcFviNMXuAeq8CGWNiXbX/tuj77ZmsTMnmr5f0J8DHiwAfq4a459m/std0IqCwkv8s3cra/bm8ePWQ6vx1Y3h4CLefE09SbBh3vr+OkvL60zyN0amdH2N7RbA6JYc/TOjFjaO7t3rb7zN7hDucPsh+IXv9gVzG9IpwuMyPO60ac1SoP/d8uJ65qw7w+CX9SOgUwhcb0vj93GSSuh0L+gDjEiL5+vdjeHj+Rp5eZN17MalfJ/41fWCtgCciXHVGDP2iQrj1vbVMe/lnXr3O6rzLkV0Zhdz/0XqCfL1YuDGda/dkMSLuxNdmsxme+mobXcP8uee83ie0R3/qsgGc98yP3PPhej6aNbI6zbRgfRqRwb4M7153P1AA5yRE0jXMnzd/Sjnhe5N9tIx/fr2dkT3CefD8E7snaAnn9evEE5cm8uAnG3l4/kaeumwAIsLR0gre+2Ufk/p3omtY41olVTU1Pp1oW7ZThM1meGrRNrqFB1TfeQvQpX0AZwRnssMWzQXPLeODVQe4fVzPkw7WI+LC+fKus3j5mqGc0cCPvTFeumYoKx8+lzvHx7d60K/PgK7tEKHe/tB/2nWEhE7BfHrrKP4+NZGdGQVMeXY5d76/jrs+SGZITChv3DDshBpsWKAPL149hOeuHMxfL+7HS9cMqbOWO7BrKAvuGE3PiCBufns1P+8+safTorIKbn1vDb7eniy4YzTRof48tmCLw658F2xIY0t6PvdMODHoA3QM8ePxi/uxbn8us3/cA1jddXy3PZMpAzo3eL3B00O4bkQsK1Oy2ZyWV2ve04u2cbS0gscu6teqNeMrh8dw5/h45q0+yDNLdwLw8dqD5JdU8JvRJzZ5dkca+E8Rn69PY9uhAu45r3ftHGt5Mb75++kz4Azyiss5JyGSuxu4mOusDkG+TOrfqVl/pH7ennW2wjiVhPh50zMiiHX7Hef5S8orWZWSw+ieHfDwEK4YHsO394xlelIXFmxIY1DXUN64YXidAV1EuHBgFNeeGdvg+xsW6MM7vxlOTFgAv3lrFWv2HStTVcd7OzMKefaKwXTvEMiDkxPYmp7P3FUHam2nrMLGvxbvoE/nEC4aWHfK5qKBUUxO7MQzS3aw7VA+SzYfpqzCdsKNeXWZntQVf29P3qrRbXfygVzmrrZabcV3DHZqO65097nxTE/qwrPf7OTdX/bx+vK9DI4JbdZrC22ZBv5TQFmFjX8t2U6/qBAuOL4mf2QnYOiWMJgf7x/HK9cOPSXbgLdFg2NCST6Q6/BO0FUp2ZRV2BgVf6yFS/tAH/42dQA/3DuO9357RrOe0YQH+fLeb88gMtiXma+vZKP94ui7v+zjs+Q0/nBuL0bbyzIlsTPDY8P45+Lt5BUfu7Fp7qr97M8u4v5Jveu9ZiMi/PXi/oT4e/GHueuZvy6V6FD/Wt111KddgDdTh0TzaXIa2UfLqLQZ/vzZJiKCfLnr3OaplJwsEeGJSxMZ1zuCP326iZSsohOaGbszDfyngPdX7udAdjH3T0o48Qebuc16jEigczv/Rt9JqOo2qGt7corK2ZdVdMK85buO4O0pDtNgMeEBTb5YXZ/IED/m3DSCEH9vrn39V+atPsDjX2xhXO+IWs0nRYQ/X9iXnKIynv3GSmUUlVXw3292Mbx7GGPruE5QU3iQL09cmsiW9HyW7zrChQOjGnXmd/3IWMoqbHywaj9zVx1gw8E8Hp7S55RK73l7evDC1UMY2DWUuA6BDm/YclcaRVrZ0dIKnvt2JyPiwhgT76D9dOY28PCCsB4tX7jT3OAYq4brKM+/fOcRhsS0r9WNQEuICvXn/ZtG4Oflyf0fbSAy2I9nZgw6oULQP7odVwzrylsrrEE7Xl++lyOFpTwwyfmLqhP7dWLqEOu+CEc3bdWnV8dgRvUM5+0V+3j6622c0T2s3vRSawnw8eKTW0ay4I7R2j1HDfpOtLI3V6RwpLCM++v6wWZut4K+V9PulFR169UxmAAfzxPy/NlHy9icls/oOm5kcrWY8ADeu+kMxidE8sq1QwkNcPzZ33Neb/y9PXl4/kZe+WEPE/p2bHQO+8lLE3n/phH0i2r8HcwzR3bnUH4JBSUVPH5x/1O2qaOnh7ikCWlbpu9GKyooKefVZXs4JyGy7r7nM7dBZP1dKqum8fQQBnRpd0KNf8Vu637CUY7OwFpIj4gg/jdzWL3LdAjy5a5z4/m/hVvxEKtDvsby8/ass8lrQ85JiGRgl3acFR9B706tf0FXOU8Dv4scyC4io6CEod3qbir51ooUcovKuWt8vOMFykusUbf6TXVRKdWgru353/I9lJRXVuftl+88QrCfFwNaoQO3xrruzFi+2JBOUrf29Grh1jSeHsJnt49u0X2q5qGB30Xu/2gDa/bl8Olto2p1ilYlv6ScV5ftZXxCJAPrak2RtQuMDSIdD76iTt7gmFDKKw2b0/IZ2q09xhiW7TzCmXHhbSIn7OPlwfxbR56yaRZ1ajr1v9ltUGpuMT/vyaKs0sZdH6xzOEjImz+lkFdczu/ra/5Wo0WPco2qJoxVef792UWk5hZXN51sCzToq8bSwO8Cn65LBeCJS/uzM6OQv3+1rdb8/JJyXlu2h3P7dCSxSz3phMztIB4QXndPiOrkRIb4ER3qX53nX7bTnt9vpQu7SrUEDfzNzBjD/HWpDIttz9VndOPGUd15c0UK323PqF7mjeUp5JdU8Ptz68jtV8ncCmFx4OXr4lK7t0FdQ1m33wr8P+06QlQ7P+I6BLZyqZRyHQ38zWxjah67Mgq5dLA17Nr9k3qT0CmY+z7cwJHCUvKKy3ltudX0rsFBQDK3a5qnBQyOCSU1t5jD+SWs2J3FqJ4dNH2iTmsa+JvZJ2tT8fH0YIq96wU/b0/+c8Ug8kvK+ePHG3h9+V4KnKntV5RB1m4N/C1gkD3P/+4v+8grLm9T+X2lmkIDfzMqr7SxYH0a5/aNrB7wAyChUwgPTEpg6dYMnv9uFxP7dWz4hpns3WAqNfC3gP7R7fDyEN60dzo2socGfnV608DfSIs2pbMro8DhvB93ZJJ1tKw6zVPTDSNjOSu+A5U2w511tduvKWOr9ahNOV3Oz9uTPp1DKCipIKFTMBHBek1Fnd60HX8j7Ms6yqx319IhyJcFd4yiczv/WvM/WZtKWKCPw8E0PDyEl68Zyu7MQuduj9cWPS1qcEwoG1PzWq2bBqVaktb4G+G9X/fj6SEUl1Vw09urKS471j4/r7icJVsPc+GAzg4HwAAI9PVqcHi9apnboH0sePs3uKg6eVVdZrRmNw1KtRQN/E4qKa9k3uoDTOzXkWevHMzmtHzu/Wh9dV/uX21Mp6zCxtQhJ6Z5mkRb9LSoyYmdefbKwZwd33CXxkq1dRr4nbRwQzq5ReVcc0Y3xvfpyAOTEli4IZ3nvt0FWGmeuIhABtR3Q5azKsut7ho08LcYHy8PLhoY1SyDzit1qtMcv5Pe+WUfcRGB1T0Z/m5MHDsOFfDvJTsI8PFkZUo2903sffLtvyvK4OuHwFYOnRKboeRKKVWbSwO/iKQABUAlUGGMSRKRfwAXAmXAbuAGY0zdI16fAjal5pF8IJdHL+xbHdhFhCenJrLnyFH+b6HVAufiQSc5EEV+Gsy7Hg6uhBG3QZ+LTrboSil1gpZI9YwzxgwyxiTZny8B+htjBgA7gAdboAwn5d1f9uHv7XlC/t7P25PZ1w6lczs/xvSKoEv7gKbvZO+P8MoYOLwZpr0Bk54ETz0hU0o1vxaPLMaYxTWe/gJMa+kyNEZecTmfJqdyyaBo2vl7nzA/MsSPb+8Zi+HEAbudYgyseBaW/sVqujlzIUQ0fkANpZRylqtr/AZYLCJrRORmB/NvBL5ytKKI3Cwiq0VkdWZmpksLWZ+P1xykpNzGNSO61bmMv49n08dm3bYQlvwZ+lwIN32rQV8p5XKuDvyjjTFDgPOB20RkTNUMEXkYqADec7SiMWa2MSbJGJMUEdE6TeyMMbz76z4Gx4Q23KFaU21bCH6hcNnr4KvD1ymlXM+lgd8Yk2p/zADmA8MBRGQmcAFwtalqCH+qsdnYteQ18jLTuOaMumv7J7sPdi2BnudqPl8p1WIaDPwicqGINPoAISKBIhJc9T9wHrBJRCYB9wMXGWOKGrvdFrNrCfEr7uUVv2eZ0j/SNftIXwdHM6HXRNdsXymlHHAmoM8AdorI0yLSmDuKOgLLRWQ9sBJYaIxZBDwPBANLRCRZRF5udKlbQOlPL1JivEliK34rn3fNTnYsBgR6jHfN9pVSyoEG8wvGmGtEJAS4EnhTRAzwBvC+McZxN5XWenuAgQ6mn/q9jmXuwHff9/yz4nJmJRQR9N0T0GMcRA1u3v3sXAxdhkFgePNuVyml6uFUCscYkw98BHwAdAYuBdaKyB0uLFurMStnU4YXW6OmEnTZ8xAYCR/fBGXNmJkqzIC0tdDrvObbplJKOcGZHP9FIjIf+B7wBoYbY87Hqs3f49ritYKSPGzr5vB55UgmDk+EgDC49CXI2gmLH26+/excYj3Ga+BXSrUsZ2r8lwHPGGMSjTH/sLfQwX5h9jcuLV1rSJ6DZ8VRPpDzmTzAGj6RuLEw8g5Y/Tpsd3jbQePtXAxBnaDTgObZnlJKOcmZwP8XrIuzAIiIv4jEAhhjvnFJqVqLzYbt19msM72ITRxFkG+NSyDnPGJ1mvbZ7Vaa5mRUlsPubyF+Auig3kqpFuZM4P8QsNV4XmmfdvrZtRSPnD28Xn4e05O61p7n5QtTX4PSAvjxHye3n/2/QGm+NuNUSrUKZwK/lzGmrOqJ/X8f1xWpFf36Mtke4WwJHcuw2PYnzo9MsGrp2xZafew01c7F4OFtpZCUUqqFORP4M0Wkun9gEbkYOOK6IrWSIzth9ze8UTqOqcO6192vfu/JkJ8K6eubvq+di6HbSO2iQSnVKpwJ/LOAh0Rkv4gcAB4AfufaYrWClbOpEG/m2sYzdUh03cv1mmgNgr79y6btJ2efNZ6upnmUUq2kwcBvjNltjBkB9AX6GGNGGmN2ub5oLagkH5M8h8Uyij7xPencrp4BzgM7QNczmh74d9p7pY7XwK+Uah1O9QwmIlOAfoBfVQrEGPO4C8vVsvZ8h5QV8nrpGG44/qKuI70nw5JHIHc/hMY0bl87F0P77hDeo2llVUqpk+TMDVwvY/XXcwcgwOWAi7qrbCXpG6jEg/1+vTm3rxMdsvWebD1uX9S4/ZQXWyNt9ZqozTiVUq3GmRz/SGPMdUCOMeYx4Eygl2uL1bLKU5PZaboweXB3fL08G16hQ0/o0Au2L2zcjvYug4oSvVtXKdWqnAn8JfbHIhGJAsqx+us5bdjS1rPJFsuUAY14Wb0nQ8pyKG7EOPFbPwefIOg2qvGFVEqpZuJM4F8gIqHAP4C1QAowx5WFalEFh/AtyWSzrRux4YHOr9d7MtgqYNdS55avKLMCf8IU8PZrWlmVUqoZ1Bv47QOwfGOMyTXGfIyV208wxvy5RUrXEtI3ALBd4ugQ1Ij70rokQWCE8617dn8DJXnQ/5QeW14p5QbqDfzGGBvwQo3npcaYPJeXqiUdsm7EymuXUPdNW454eEKvSbBzqVWbb8jGj8A/zOrXXymlWpEzqZ5vROQyaVRUbEPS15PmGUX79k0YDKX3ZCjNg30/1b9c2VHrzKDvxeDp3bRyKqVUM3Em8P8Oq1O2UhHJF5ECEcl3cblaTvoGtti6ERXahLx73Fjw8m+4q+Ydi6C8CPpf1pQSKqVUs3Lmzt1gY4yHMcbHGBNifx7SEoVzueIcyN3HmrJuRIcGNH59nwArdbP9y/o7bdv4MQR3tvrnUUqpVtbgnbsiMsbRdGPMj81fnBZ2aCMAm003LmxKjR+sdM/2L61tdXYwqEpxLuxaAsNusq4LKKVUK3Omy4b7avzvBwwH1gDnuKRELcneomezLZZZ7evpn6c+vSYBYgV/R4F/6wKoLINETfMopU4NDQZ+Y8yFNZ+LSFfgP85sXERSgAKswVsqjDFJIhIGzAVise4JmG6MyWlUqZvLoQ0U+XUkq6Qd0aFNDPxBEdB9DKx43mqj3ymx9vxNH1t980QNOfnyKqVUM3Dm4u7xDgJ9GrH8OGPMIGNMkv35H7HuDYgHvrE/bx3p6znk3wsR6NTuJG6quuQl8AuBd6dZHbdVKcyAvT9YF3VP00ZRSqm2x5lO2p4TkWftf88Dy7Du4G2qi4G37P+/BVxyEttqurIiOLKDPV5xRAT5OtdHT13aRcM1H1udsL17GRRlW9M3fwrGBol605ZS6tThTI1/NVZOfw3wM/CAMeYaJ7dvgMUiskZEbrZP62iMSbf/fwjo6GhFEblZRFaLyOrMzEwnd9cIGVvA2NhoiyW6qfn9miL7wJVzICcF3r/SOghs+ggi+1nzlFLqFOHMxd2PgBJjTCWAiHiKSIAxpsiJdUcbY1JFJBJYIiLbas40xhgRcdgO0hgzG5gNkJSUdBID3NYhPRmAX4u7ENWlGQI/QOxouPQV+OhGmDMDDvwK5zzSPNtWSqlm4tSdu0DNyOgPONUzmTEm1f6YAczHahF0WEQ6A9gfMxpT4GaTvgHjF8ra/CC6NPXCriP9p8LEJ63cPuhNW0qpU44zNX4/Y0xh1RNjTKGINHi3k4gEAh7GmAL7/+cBjwOfA9cDf7c/ftakkp+sQxsoj0ykLNcQ1ZyBH+DMW607dfPTIKx7825bKaVOkjOB/6iIDDHGrAUQkaFAsRPrdQTm27v48QLmGGMWicgqYJ6I/AbYB0xvWtFPQmU5HN5Mbt+ZAE1vylmfMfc2/zaVUqoZOBP4fw98KCJpWEMvdsIairFexpg9wEAH07OA8Y0sZ/PK3A6VZaT5xQM0f41fKaVOYc7cwLVKRBKA3vZJ240x5a4tlosdsu7Y3enZAyhpnlY9SinVRjjTjv82INAYs8kYswkIEpFbXV80F0pfD94BbCmNIMjXixA/Z058lFLq9OBMq56bjDHVA8vau1e4yXVFagHpG6BTIql5ZUSH+jduABallGrjnAn8njUHYRERT6ARYxSeYmw2qyfNTgNIzS1uWj/8SinVhjkT+BcBc0VkvIiMB94HGhh55BSWsxfKCqDzANJyizW/r5RyO84ktx8AbgZm2Z9vwGrZ0zalW2PsFnfoT05RurboUUq5HWdG4LIBv2J1oTwcqx/+ra4tlgvZe89M84wCXNSGXymlTmF11vhFpBdwpf3vCFYf+hhjxrVM0VykOAc8fThQYF220MCvlHI39aV6tmF1wXyBMWYXgIjc3SKlcqWSXPBvT2peCYDm+JVSbqe+VM9UIB34TkRetV/YbfvtHotzwC+UtNxivDyEyGBt1aOUci91Bn5jzKfGmCuABOA7rK4bIkXkJRE5r6UK2OyKc6waf04xndr54enR9o9lSinVGM5c3D1qjJljH3u3C7AOq6VP22QP/Gm5JdqiRynllho15q4xJscYM9sY07qdrJ2MYnuOP7e4efvhV0qpNqIpg623bcU52PxCOZSvNX6llHtyr8BfWQ5lhRR6BFNpM9qiRynlltwr8Bdbfc1lm0BA++FXSrknNwv8OQBkllsBX2/eUkq5I7cM/OllVtt97ZlTKeWO3DLwHyjxIyzQhwAfHYBFKeV+3DLwpxz10dq+UsptuTzwi4iniKwTkS/sz8eLyFoRSRaR5SLS09VlqGYP/LsKvDW/r5RyWy1R47+L2t04vwRcbYwZBMwB/tQCZbAU52AQduaJtuhRSrktlwZ+EekCTAFeqzHZACH2/9sBaa4sQy0luRi/UArLjNb4lVJuy9VXN/8D3A8E15j2W+BLESkG8oERjlYUkZuxRv4iJiameUpTnEO5TztAm3IqpdyXy2r8InIBkGGMWXPcrLuBycaYLsAbwL8drW/vEyjJGJMUERHRPIUqzqHE0zoG6V27Sil35coa/yjgIhGZDPgBISKyEEgwxvxqX2Yu1mDuLaM4h0IPK/B3bqeBXynlnlxW4zfGPGiM6WKMiQWuAL4FLgba2Yd1BJhAS47fW5xDgQThIRAW6NNiu1VKqVNJi97BZIypEJGbgI9FxAbkADe2WAGKc8gJCCIs0EcHYFFKua0WCfzGmO+B7+3/zwfmt8R+a7HZoDiXLL8AwgN9W3z3Sil1qnCfO3dL8wBDZnkA4UGa5lFKuS/3Cfz2LpkPlfsTHqQ1fqWU+3KjwG9115Ba6ku4XthVSrkxtwv86aX+GviVUm7N7QJ/LkGa6lFKuTW3C/x5Jkgv7iql3JobBX7r4m4egXTQwK+UcmNuFPhzKPcMoBwvbcevlHJr7hP4S3Ip8bJ6g9ZUj1LKnblP4C/OocgzGB8vD4J8daxdpZT7cqvAXyBBhAf6IKL99Cil3JdbBf4cbdGjlFLuFfizK7WDNqWUco9ktzFQnEMG2kGbUkq5R+AvL4LKMg7Z/Omgd+0qpdyce6R67HftHqkM1H56lFJuz00Cv/2uXROo/fQopdyemwR+ez89aI1fKaXcKvDnanNOpZRyx8CvqR6llHtzr8CvqR6llHJ94BcRTxFZJyJf2J+LiDwhIjtEZKuI3OnqMlCcQ4V44+kbiJ+3p8t3p5RSp7KWaMd/F7AVCLE/nwl0BRKMMTYRiXR5CYpzOOoRTHiApnmUUsqlNX4R6QJMAV6rMfkW4HFjjA3AGJPhyjIAUJJLgQRrmkcppXB9quc/wP2Arca0HsAMEVktIl+JSLyjFUXkZvsyqzMzM0+uFMU55JkAvbCrlFK4MPCLyAVAhjFmzXGzfIESY0wS8CrwuqP1jTGzjTFJxpikiIiIkytMcQ5ZNr2wq5RS4Noc/yjgIhGZDPgBISLyLnAQ+MS+zHzgDReWAQBTnENmRZy24VdKKVwY+I0xDwIPAojIWOBeY8w1IvJ3YBywFzgb2OGqMlQryiHHBGqXzEq5SHl5OQcPHqSkpKS1i+KW/Pz86NKlC97e3k4t3xq9c/4deE9E7gYKgd+6dG8VZUj5UXJNEPFa41fKJQ4ePEhwcDCxsbE6wl0LM8aQlZXFwYMH6d69u1PrtEjgN8Z8D3xv/z8Xq6VPyyixOmjLJUi7ZFbKRUpKSjTotxIRITw8nMY0gjn979yt1TOn1viVchUN+q2nse+9GwT+mj1zao1fKaXcKPAH0T7AuQsfSil1OnObwG/zDcXL8/R/uUqpur355pvcfvvtLt/P999/zwUXXODy/TTV6T/mrj3wewaFt3JBlHIPjy3YzJa0/GbdZt+oEB69sF+zbtOdnf5V4OIcbAh+gaGtXRKllAulpKSQkJDAzJkz6dWrF1dffTVLly5l1KhRxMfHs3LlylrLz5w5k1mzZpGUlESvXr344osv6tz2iBEj2Lx5c/XzsWPHsnr1alauXMmZZ57J4MGDGTlyJNu3b3eqrHWtV1lZyb333kv//v0ZMGAAzz33HACrVq1i5MiRDBw4kOHDh1NQUNDYt6cWt6jxFxBEeLB/a5dEKbfQmjXzXbt28eGHH/L6668zbNgw5syZw/Lly/n888958sknueSSS2otn5KSwsqVK9m9ezfjxo1j165d+Pn5nbDdGTNmMG/ePB577DHS09NJT08nKSmJ/Px8li1bhpeXF0uXLuWhhx7i448/brCcCQkJDtebPXs2KSkpJCcn4+XlRXZ2NmVlZcyYMYO5c+cybNgw8vPz8fc/uXjmFoE/F23KqZQ76N69O4mJiQD069eP8ePHIyIkJiaSkpJywvLTp0/Hw8OD+Ph44uLi2LZtG4MGDXK43Hnnncdjjz3GvHnzmDZtGgB5eXlcf/317Ny5ExGhvLzcqXLWtd7SpUuZNWsWXl5WaA4LC2Pjxo107tyZYcOGARASElLndp112qd6bMU55NgCtCmnUm7A1/fY79zDw6P6uYeHBxUVFScsf3z797raw0dHRxMeHs6GDRuYO3cuM2bMAOCRRx5h3LhxbNq0iQULFjjdZUVT12sup33grzyaTZ4Osq6UcuDDDz/EZrOxe/du9uzZQ+/evetcdsaMGTz99NPk5eUxYMAAwKq5R0dHA1aLIWfVtd6ECRN45ZVXqg9S2dnZ9O7dm/T0dFatWgVAQUGBw4NYY5z2gd9WlGPvrkEDv1KqtpiYGIYPH87555/Pyy+/7DC/X2XatGl88MEHTJ8+vXra/fffz4MPPsjgwYMbFYzrWu+3v/0tMTExDBgwgIEDBzJnzhx8fHyYO3cud9xxBwMHDmTChAknfYYgxpiT2kBLSEpKMqtXr27SuuVPdmNO0TD6/GY2w7uHNXPJlFIAW7dupU+fPq1djEaZOXMmF1xwQXW+vq1z9BmIyBr72Ce1nN41fpsNr7I8ctFUj1JKVTm9W/WU5iEY8kwQHfTirlKqBkc5+a+//poHHnig1rTu3bszf/78Ju3jjTfe4L///W+taaNGjeKFF15o0vaay+kd+O137eZLECH+p/dLVUqdvIkTJzJx4sRm294NN9zADTfc0Gzbay6nd6rH3iWzzS9Uu4xVSim70zzwWzV+D//2rVwQpZQ6dbhF4PcM1NY8SilVxS0Cv0+w9syplFJVTvPAb+X4/TTwK6VaSFXPnaey07qpS/nRLEqNH+1DAlu7KEq5j6/+CIc2Nu82OyXC+X9v3m26MZfX+EXEU0TWicgXx01/VkQKXbnvQv8ufGcbpG34lXIDb7/9dnVXB9deey0zZ87kzjvvZOTI52HKnQAACf1JREFUkcTFxfHRRx8B1uhYY8eOZdq0aSQkJHD11VdTVw8GixYt4vLLL69+XnNkrVtuuYWkpCT69evHo48+6nQ561rPUZ/7dfXPf9KMMS79A/4AzAG+qDEtCXgHKHRmG0OHDjVNsW5/jun2wBdm6ZZDTVpfKeWcLVu2tOr+N23aZOLj401mZqYxxpisrCxz/fXXm2nTppnKykqzefNm06NHD2OMMd99950JCQkxBw4cMJWVlWbEiBFm2bJlDrdbXl5uunbtagoLC40xxsyaNcu888471fswxpiKigpz9tlnm/Xr1xtjjDn77LPNqlWr6iyro/VKS0tN9+7dzcqVK40xxuTl5Zny8nLz4osvmssuu8yUl5fXWtcRR58BsNo4iKkurfGLSBdgCvBajWmewD+A+125b4CswlIAwoO0xq/U6ezbb7/l8ssvp0OHDoDVjz3AJZdcgoeHB3379uXw4cPVyw8fPpwuXbrg4eHBoEGDHPbVD+Dl5cWkSZNYsGDB/7d397FV3XUcx98fL8WWB3kOQdsJZkQCodCmgU0WOzEaxGaEOLMu+2MYnlyGYuLDICQmJv6DIbohiwn4AMFFBtNNAgEHjBkTDc8P8mAZWty6AC1VJF1IN/DrH+fXeSkttPfe9vac830lNz3nd+85+X3T0+/99Xfv+f64desWu3fvZsGCBQBs376d6upqqqqqOHv2LOfOnetRX7s6rqGh4a6a+x2LtCxfvvyO+vyF0Ndz/M8TJfjhWW0rgJ1mdvleN1VJWgYsg6iCXi5a294HYMxQr9PjXBpl1+e3rOmc7PZMJnPPypr19fVs2LCB0aNHU1NTw/Dhw2lsbGTdunUcOXKEUaNGsWjRoh5VzMz1uELrsxG/pDqg2cyOZbV9HPgqcN+JKjPbaGY1ZlYzbty4nPpw7b2OEb8nfueSbO7cuezYsYPW1lYgqmNfKLW1tRw/fpxNmzZRX18PwI0bNxg6dCgjRozg6tWr7Nmzp0fn6u647mrud1WfvxD6csQ/B3hM0nygFPgYcBZoBy6G0f4QSRfN7MG+6MC/2t5nyOAMQwYn+stLzqXetGnTWLNmDbW1tWQyGaqqqgp27kwmQ11dHZs3b2bLli0AzJgxg6qqKqZMmUJFRQVz5szp0bm6Oy675v7NmzcpKytj//79LFmyhAsXLlBZWUlJSQlLly5lxYoVecfUL/X4JT0KfMfM6jq1t5nZsPsdn2s9/m2H3+bE29dZ+3hlr491zvVcHOvxJ01v6vEneihcP+sB6mfl9vmAc84lVb8kfjN7E3izi/b7jvadc64/LFy4kMbGxjva1q5dm3OZ5tmzZ9Pe3n5H29atW5k+fXrOfSyURI/4nXP9x8xiXf4818VWunPo0KGCnu9eejtln+xaPc65flFaWkpra2uvE5DLn5nR2tp6z4XiO/MRv3Mub+Xl5TQ1NdHS0lLsrqRSaWkp5eXlPX69J37nXN5KSkqYNGlSsbvhesinepxzLmU88TvnXMp44nfOuZTplzt38yWpBfhnjoePBa4VsDvFlqR4khQLeDwDWZJigZ7H80kzu6vYWSwSfz4kHe3qluW4SlI8SYoFPJ6BLEmxQP7x+FSPc86ljCd+55xLmTQk/o3F7kCBJSmeJMUCHs9AlqRYIM94Ej/H75xz7k5pGPE755zL4onfOedSJtGJX9I8SQ2SLkpaVez+9JakX0pqlnQmq220pH2S3go/RxWzjz0lqULSQUnnJJ2VtDK0xy4eSaWSDks6FWL5QWifJOlQuN5elhSrxZ4lZSSdkLQr7Mc2HkmXJP1V0klJR0Nb7K41AEkjJb0i6W+Szkt6ON9YEpv4JWWAF4EvAVOBJyVNLW6vem0zMK9T2yrggJlNBg6E/Ti4BXzbzKYCDwHPht9HHONpB+aa2QxgJjBP0kPAWuAnYQ3pfwOLi9jHXKwEzmftxz2ez5nZzKzvu8fxWgN4AdhrZlOAGUS/o/xiMbNEPoCHgT9k7a8GVhe7XznEMRE4k7XfAEwI2xOAhmL3Mce4fg98Ie7xAEOA48BsojspB4X2O66/gf4AykMCmQvsAhTzeC4BYzu1xe5aA0YAjYQv4hQqlsSO+IFPAO9k7TeFtrgbb2aXw/YVYHwxO5MLSROBKuAQMY0nTIucBJqBfcDfgetmdiu8JG7X2/PA94D/hv0xxDseA16XdEzSstAWx2ttEtAC/CpMw/1c0lDyjCXJiT/xLHq7j9X3cSUNA34LfMvMbmQ/F6d4zOy2mc0kGinPAqYUuUs5k1QHNJvZsWL3pYAeMbNqoqneZyV9NvvJGF1rg4Bq4GdmVgW8R6dpnVxiSXLifxeoyNovD21xd1XSBIDws7nI/ekxSSVESf8lM/tdaI5tPABmdh04SDQVMlJSx+JGcbre5gCPSboEbCOa7nmB+MaDmb0bfjYDrxK9OcfxWmsCmsysYwHfV4jeCPKKJcmJ/wgwOXwzYTBQD+wscp8KYSfwdNh+mmiufMBTtAr3L4DzZvbjrKdiF4+kcZJGhu0yos8qzhO9ATweXhaLWADMbLWZlZvZRKK/kzfM7CliGo+koZKGd2wDXwTOEMNrzcyuAO9I+nRo+jxwjnxjKfaHF338wch84ALR/OuaYvcnh/7/BrgMfED0zr+YaO71APAWsB8YXex+9jCWR4j+HT0NnAyP+XGMB6gEToRYzgDfD+2fAg4DF4EdwEeL3dccYnsU2BXneEK/T4XH2Y6//Thea6HfM4Gj4Xp7DRiVbyxessE551ImyVM9zjnnuuCJ3znnUsYTv3POpYwnfuecSxlP/M45lzKe+F2qSbodKjh2PApWuEvSxOzKqs4NFIPu/xLnEu2mRaUXnEsNH/E714VQz/1Hoab7YUkPhvaJkt6QdFrSAUkPhPbxkl4NNfpPSfpMOFVG0qZQt//1cKcvkr4Z1iY4LWlbkcJ0KeWJ36VdWaepnieynvuPmU0HNhBVrwT4KbDFzCqBl4D1oX098EeLavRXE90xCjAZeNHMpgHXga+E9lVAVTjP1/sqOOe64nfuulST1GZmw7pov0S02Mo/QnG5K2Y2RtI1ojroH4T2y2Y2VlILUG5m7VnnmAjss2ixDCQ9B5SY2Q8l7QXaiG7Bf83M2vo4VOc+5CN+57pn3Wz3RnvW9m3+/7nal4lWiKsGjmRVwXSuz3nid657T2T9/EvY/jNRBUuAp4A/he0DwDPw4SItI7o7qaSPABVmdhB4jmiVpbv+63Cur/gow6VdWVhJq8NeM+v4SucoSaeJRu1PhrZvEK2G9F2ilZG+FtpXAhslLSYa2T9DVFm1Kxng1+HNQcB6i+r6O9cvfI7fuS6EOf4aM7tW7L44V2g+1eOccynjI37nnEsZH/E751zKeOJ3zrmU8cTvnHMp44nfOedSxhO/c86lzP8A2TADaozOrTEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7urbNyRNhxv"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}